
import json
import os
import sys
import threading
import time
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
from typing import Dict, List, Optional, Any
import zipfile
import subprocess
import re
from tempfile import NamedTemporaryFile
from docx.oxml import parse_xml
import traceback

_FILE_LOCK = threading.RLock()
_OUTPUT_DIR_LOCK = threading.RLock()

def get_app_path():
    """L·∫•y ƒë∆∞·ªùng d·∫´n ch·ª©a file .exe ho·∫∑c script"""
    if getattr(sys, 'frozen', False):
        return os.path.dirname(sys.executable)
    return os.path.dirname(os.path.abspath(__file__))
def find_pandoc_executable():
    """
    T√¨m pandoc.exe theo th·ª© t·ª± ∆∞u ti√™n:
    1. Th∆∞ m·ª•c 'pandoc' c·∫°nh tool (cho b·∫£n build)
    2. PATH h·ªá th·ªëng (cho m√¥i tr∆∞·ªùng dev)
    """
    app_path = get_app_path()
    
    # 1. T√¨m trong th∆∞ m·ª•c c·ª•c b·ªô 'pandoc' (∆∞u ti√™n cao nh·∫•t)
    local_pandoc = os.path.join(app_path, 'pandoc', 'pandoc.exe')
    if os.path.isfile(local_pandoc):
        # print(f"‚úÖ S·ª≠ d·ª•ng Pandoc c·ª•c b·ªô: {local_pandoc}")
        return local_pandoc
    
    # 2. Fallback: T√¨m trong PATH h·ªá th·ªëng (cho dev)
    import shutil
    system_pandoc = shutil.which('pandoc')
    if system_pandoc:
        # print(f"‚ö†Ô∏è S·ª≠ d·ª•ng Pandoc h·ªá th·ªëng: {system_pandoc}")
        return system_pandoc
    
    # 3. Kh√¥ng t√¨m th·∫•y
    print("‚ùå KH√îNG T√åM TH·∫§Y PANDOC!")
    return None

def latex_to_omml_via_pandoc(latex_math_dollar):
    """Chuy·ªÉn ƒë·ªïi LaTeX sang OMML qua Pandoc"""
    pandoc_exe = find_pandoc_executable()
    
    if not pandoc_exe:
        print("‚ùå Pandoc kh√¥ng kh·∫£ d·ª•ng, b·ªè qua equation")
        return None
    
    try:
        # Chu·∫©n h√≥a input (lo·∫°i b·ªè k√Ω t·ª± l·∫°)
        latex_clean = latex_math_dollar.strip()
        
        # T·∫°o file t·∫°m v·ªõi encoding UTF-8 BOM ƒë·ªÉ tr√°nh l·ªói
        with NamedTemporaryFile(mode='w', suffix=".docx", delete=False, encoding='utf-8') as temp_docx:
            temp_path = temp_docx.name
        
        # Ch·∫°y Pandoc v·ªõi error handling t·ªët h∆°n
        result = subprocess.run(
            [pandoc_exe, '--from=latex', '--to=docx', '-o', temp_path],
            input=latex_clean,
            text=True,
            encoding='utf-8',
            capture_output=True,
            timeout=10,  # Timeout 10s ƒë·ªÉ tr√°nh treo
            creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
        )
 
        if result.returncode != 0:
            error_msg = result.stderr.strip() if result.stderr else "Unknown error"
            print(f"‚ö†Ô∏è Pandoc error (code {result.returncode}): {error_msg}")
            
            # Ki·ªÉm tra l·ªói ph·ªï bi·∫øn
            if "not found" in error_msg.lower() or "cannot find" in error_msg.lower():
                print("   ‚Üí Thi·∫øu DLL dependencies. Ki·ªÉm tra l·∫°i folder pandoc/")
            elif "syntax" in error_msg.lower():
                print(f"   ‚Üí LaTeX syntax error: {latex_clean[:50]}...")
            
            return None
        
        # Ki·ªÉm tra file output c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(temp_path) or os.path.getsize(temp_path) == 0:
            print(f"‚ö†Ô∏è Pandoc kh√¥ng t·∫°o file output h·ª£p l·ªá")
            return None
           
        # ƒê·ªçc XML t·ª´ DOCX
        with zipfile.ZipFile(temp_path, 'r') as z:
            xml_content = z.read('word/document.xml').decode('utf-8')
        
        # D·ªçn d·∫πp file t·∫°m
        try:
            os.remove(temp_path)
        except:
            pass
       
        # T√¨m equation XML
        match = re.search(r'(<m:oMath[^>]*>.*?</m:oMath>)', xml_content, re.DOTALL)
        
        if not match:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y equation trong output: {latex_clean[:30]}...")
            return None
            
        return match.group(1)
   
    except subprocess.TimeoutExpired:
        print(f"‚ö†Ô∏è Pandoc timeout (>10s)")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói latex_to_omml: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None



def process_text_with_latex(text, paragraph, bold=False):
    """
    X·ª≠ l√Ω text c√≥ c√¥ng th·ª©c LaTeX
    VERSION ·ªîN ƒê·ªäNH - Copy t·ª´ test_res.py (KH√îNG c√≥ repair_broken_latex)
    """
    if not text:
        return
    
    # L√†m s·∫°ch HTML tags
    text = text.replace("<br>", "\n").replace("<br/>", "\n") \
               .replace("<Br>", "\n").replace("<Br/>", "\n")
    text = re.sub(r'</?(div|p|u|span|font|i|b)\b[^>]*>', '', text)
    text = text.replace("&nbsp;", "").replace("&lt;", "").replace("&gt;", "")
    
    # T√°ch text v√† LaTeX
    pattern = r'(\$[^$]+\$|\\\[.*?\\\])'
    parts = re.split(pattern, text)
    
    for part in parts:
        if not part:
            continue
        
        # Ph·∫ßn LaTeX
        if part.startswith('$') or part.startswith('\\['):
            try:
                latex_expr = clean_latex_math(part)
                insert_equation_into_paragraph(latex_expr, paragraph)
            except Exception as e:
                # Fallback: th√™m text thu·∫ßn
                run = paragraph.add_run(part)
                if bold:
                    run.bold = True
        # Ph·∫ßn text th∆∞·ªùng
        else:
            cleaned_part = re.sub(r'^\s*/', '', part)
            run = paragraph.add_run(cleaned_part)
            if bold:
                run.bold = True


def insert_equation_into_paragraph(latex_math_dollar, paragraph):
    """Ch√®n c√¥ng th·ª©c to√°n h·ªçc v√†o paragraph"""
    omml_str = latex_to_omml_via_pandoc(latex_math_dollar)
    
    if not omml_str:
        # Fallback: Th√™m text thu·∫ßn n·∫øu kh√¥ng convert ƒë∆∞·ª£c
        paragraph.add_run(f" [{latex_math_dollar}] ")
        return
    
    # Th√™m namespace n·∫øu thi·∫øu
    if 'xmlns:m=' not in omml_str:
        omml_str = re.sub(
            r'<m:oMath',
            r'<m:oMath xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"',
            omml_str,
            count=1
        )
    
    try:
        omml_element = parse_xml(omml_str)
        run = paragraph.add_run()
        run._r.append(omml_element)
    except Exception as e:
        print(f"L·ªói ch√®n equation: {e}")
        paragraph.add_run(f" [{latex_math_dollar}] ")


def clean_latex_math(latex_raw):
    latex_raw = re.sub(r'\\/', '', latex_raw)
    latex_raw = re.sub(r'\\operatorname\s*{\s*([^}]*)\s*}',
                       lambda m: m.group(1).replace(' ', ''), latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*{(\d+)}\s*\\of\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*\\sqrt\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'([a-zA-Z])\s*\\frac\s*{([^}]+)}\s*{([^}]+)}',
                       r'\1^{\\frac{\2}{\3}}', latex_raw)
    latex_raw = re.sub(r'\\sp\s*{([^}]*)}', r'^{\1}', latex_raw)
    latex_raw = re.sub(r'{\\bf\s*([^}]*)}', r'\1', latex_raw)
    latex_raw = re.sub(r'\\\s*log', r'\\log', latex_raw)
    latex_raw = re.sub(r'\\bigskip', '', latex_raw)
    latex_raw = re.sub(r'\\nonumber', '', latex_raw)
    latex_raw = latex_raw.replace(r'\?', '?')
    latex_raw = re.sub(r'\\cdot\s*(?=\w)', r'\\cdot ', latex_raw)
    latex_raw = latex_raw.replace(r'\dotstan', r'\cdot \tan')
    latex_raw = re.sub(r'(?<!\\)(\bln\b|\blog\b|\bsin\b|\bcos\b|\btan\b|\blog_{?\d*}?)',
                       r'\\\1', latex_raw)
    latex_raw = re.sub(r'(\\Leftrightarrow|\\Rightarrow|\\rightarrow)(?=\w)', r'\1 ', latex_raw)
    latex_raw = latex_raw.replace(r'\\n', r'\n')
    
    latex_raw = latex_raw.strip()
    # ‚úÖ KH√ÅC BI·ªÜT: Version c≈© KH√îNG replace \n v√† \r
    # latex_raw = latex_raw.replace('\n', ' ').replace('\r', '')  # ‚Üê X√ìA D√íNG N√ÄY
    
    if not (latex_raw.startswith('$') and latex_raw.endswith('$')):
        latex_raw = f"${latex_raw}$"
    
    return latex_raw

def ensure_output_folder_for_batch(batch_name):
    """T·∫°o folder ri√™ng cho batch"""
    base_path = get_app_path()
    output_base = os.path.join(base_path, "output")
    batch_folder = os.path.join(output_base, batch_name)
    
    with _OUTPUT_DIR_LOCK:
        os.makedirs(output_base, exist_ok=True)
        os.makedirs(batch_folder, exist_ok=True)
    
    return batch_folder

def save_document_securely(doc, batch_name, file_name):
    """L∆∞u file DOCX v·ªõi thread-safety"""
    batch_folder = ensure_output_folder_for_batch(batch_name)
    if not batch_folder:
        return None

    output_path = os.path.join(batch_folder, f"{file_name}.docx")
    
    with _FILE_LOCK:
        max_retries = 3
        for retry_count in range(max_retries):
            try:
                doc.save(output_path)
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    print(f"‚úÖ ƒê√£ l∆∞u file: {output_path} ({file_size} bytes)")
                    return output_path
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói l∆∞u file l·∫ßn {retry_count + 1}: {e}")
                if retry_count < max_retries - 1:
                    time.sleep(0.5)
        
        print(f"‚ùå Kh√¥ng th·ªÉ l∆∞u file sau {max_retries} l·∫ßn th·ª≠")
        return None

def clean_json_string(text: str) -> str:
    if not text:
        return ""

    text = text.strip()

    # B∆Ø·ªöC 1: D√πng Regex ƒë·ªÉ b·∫Øt n·ªôi dung trong ```json ... ``` (n·∫øu c√≥)
    # re.DOTALL gi√∫p d·∫•u ch·∫•m (.) kh·ªõp v·ªõi c·∫£ d√≤ng m·ªõi (\n)
    # re.IGNORECASE ƒë·ªÉ b·∫Øt c·∫£ ```JSON v√† ```json
    pattern = r"```(?:json)?(.*?)```"
    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
    
    if match:
        # N·∫øu t√¨m th·∫•y markdown, l·∫•y n·ªôi dung b√™n trong
        text = match.group(1).strip()
    
    # B∆Ø·ªöC 2: "SƒÉn" JSON b·∫±ng c√°ch t√¨m d·∫•u { ƒë·∫ßu ti√™n v√† } cu·ªëi c√πng
    # B∆∞·ªõc n√†y c·ª±c quan tr·ªçng cho m√¥n T·ª± nhi√™n khi AI hay n√≥i nh·∫£m tr∆∞·ªõc/sau JSON
    start_idx = text.find('{')
    end_idx = text.rfind('}')

    if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
        # C·∫Øt l·∫•y ƒë√∫ng ph·∫ßn t·ª´ { ƒë·∫øn }
        return text[start_idx : end_idx + 1]

    # Tr∆∞·ªùng h·ª£p t·ªá nh·∫•t: Tr·∫£ v·ªÅ nguy√™n g·ªëc ƒë·ªÉ c√°c h√†m repair (AI s·ª≠a l·ªói) x·ª≠ l√Ω ti·∫øp
    return text

def repair_json_with_ai(broken_json_str: str, client) -> str:
    """G·ª≠i JSON l·ªói cho AI s·ª≠a"""
    print("‚ö†Ô∏è JSON l·ªói. ƒêang y√™u c·∫ßu AI s·ª≠a...")
    prompt_fix = f"""
ƒêo·∫°n JSON sau b·ªã l·ªói c√∫ ph√°p:

{broken_json_str}

NHI·ªÜM V·ª§:
1. S·ª≠a l·ªói c√∫ ph√°p JSON (escape quotes, th√™m ph·∫©y, ƒë√≥ng ngo·∫∑c)
2. KH√îNG thay ƒë·ªïi n·ªôi dung Ti·∫øng Vi·ªát
3. KH√îNG thay ƒë·ªïi c√¥ng th·ª©c LaTeX (gi·ªØ nguy√™n \\frac, \\sqrt...)
4. CH·ªà TR·∫¢ V·ªÄ JSON ƒê√É S·ª¨A (kh√¥ng markdown, kh√¥ng gi·∫£i th√≠ch)
    """
    repaired_text = client.send_data_to_check(prompt_fix)
    return clean_json_string(repaired_text)
def sanitize_latex_json(text: str) -> str:
    """
    Sanitize JSON ch·ª©a LaTeX m·ªôt c√°ch AN TO√ÄN
    
    Chi·∫øn l∆∞·ª£c:
    1. Ch·ªâ x·ª≠ l√Ω B√äN TRONG chu·ªói JSON (gi·ªØa d·∫•u ngo·∫∑c k√©p)
    2. Gi·ªØ nguy√™n ph·∫ßn c·∫•u tr√∫c JSON (keys, colons, brackets)
    3. Escape backslash KH√îNG ph·∫£i JSON escape h·ª£p l·ªá
    """
    
    # Danh s√°ch escape sequences h·ª£p l·ªá trong JSON spec
    VALID_JSON_ESCAPES = {
        '\\\\', '\\"', '\\/', '\\b', '\\f', '\\n', '\\r', '\\t'
    }
    
    def fix_string_content(match):
        """
        X·ª≠ l√Ω n·ªôi dung B√äN TRONG chu·ªói JSON (gi·ªØa d·∫•u ngo·∫∑c k√©p)
        match.group(0) = to√†n b·ªô "..." (c√≥ d·∫•u ")
        match.group(1) = n·ªôi dung gi·ªØa d·∫•u " (kh√¥ng c√≥ d·∫•u ")
        """
        full_match = match.group(0)
        content = match.group(1)
        
        # N·∫øu chu·ªói r·ªóng, gi·ªØ nguy√™n
        if not content:
            return full_match
        
        result = []
        i = 0
        
        while i < len(content):
            char = content[i]
            
            if char == '\\':
                # Ki·ªÉm tra c√≥ ph·∫£i escape h·ª£p l·ªá kh√¥ng
                if i + 1 < len(content):
                    next_char = content[i + 1]
                    two_chars = char + next_char
                    
                    # Tr∆∞·ªùng h·ª£p 1: JSON escape h·ª£p l·ªá (\\, \", \n, \t...)
                    if two_chars in VALID_JSON_ESCAPES:
                        result.append(two_chars)
                        i += 2
                        continue
                    
                    # Tr∆∞·ªùng h·ª£p 2: Unicode escape (\uXXXX)
                    if next_char == 'u' and i + 5 < len(content):
                        hex_part = content[i+2:i+6]
                        if len(hex_part) == 4 and all(c in '0123456789ABCDEFabcdef' for c in hex_part):
                            result.append(content[i:i+6])  # \uXXXX
                            i += 6
                            continue
                    
                    # Tr∆∞·ªùng h·ª£p 3: LaTeX command (VD: \frac, \sqrt, \sin)
                    # ‚Üí Escape th√†nh \\
                    result.append('\\\\')
                    i += 1
                else:
                    # Backslash ·ªü cu·ªëi chu·ªói ‚Üí Escape
                    result.append('\\\\')
                    i += 1
            else:
                result.append(char)
                i += 1
        
        # Tr·∫£ v·ªÅ chu·ªói ƒë√£ fix (V·∫™N C√ì d·∫•u ngo·∫∑c k√©p)
        return '"' + ''.join(result) + '"'
    
    # Regex t√¨m t·∫•t c·∫£ chu·ªói JSON: "..."
    # (?:[^"\\]|\\.)* nghƒ©a l√†: (kh√¥ng ph·∫£i " ho·∫∑c \) HO·∫∂C (\ theo sau b·∫•t k·ª≥ k√Ω t·ª± n√†o)
    string_pattern = r'"((?:[^"\\]|\\.)*)"'
    
    sanitized = re.sub(string_pattern, fix_string_content, text)
    
    return sanitized

def parse_json_safely(json_str: str, client) -> Optional[Dict]:
    """Parse JSON an to√†n v·ªõi Sanitization v√† Retry AI"""
    # 1. Clean markdown
    cleaned_str = clean_json_string(json_str)
    
    # 2. B∆∞·ªõc quan tr·ªçng: Sanitize LaTeX backslashes b·∫±ng thu·∫≠t to√°n (nhanh v√† ch√≠nh x√°c h∆°n AI)
    sanitized_str = sanitize_latex_json(cleaned_str)
    
    # Th·ª≠ parse l·∫ßn 1 (v·ªõi chu·ªói ƒë√£ sanitize)
    try:
        return json.loads(sanitized_str, strict=False)
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói JSON l·∫ßn 1 (Logic): {e}")
        # Debug: In ra ƒëo·∫°n l·ªói ƒë·ªÉ ki·ªÉm tra n·∫øu c·∫ßn
        start = max(0, e.pos - 20)
        end = min(len(sanitized_str), e.pos + 20)
        print(f"Context: ...{sanitized_str[start:end]}...")
    
    # Th·ª≠ s·ª≠a b·∫±ng AI (Fallback cu·ªëi c√πng)
    try:
        # L∆∞u √Ω: G·ª≠i chu·ªói g·ªëc (cleaned_str) ho·∫∑c chu·ªói ƒë√£ sanitize t√πy chi·∫øn l∆∞·ª£c. 
        # Th∆∞·ªùng g·ª≠i chu·ªói g·ªëc ƒë·ªÉ AI t·ª± ƒë·ªãnh d·∫°ng l·∫°i t·ª´ ƒë·∫ßu s·∫Ω an to√†n h∆°n v·ªÅ ng·ªØ nghƒ©a.
        repaired_str = repair_json_with_ai(cleaned_str, client)
        
        # Sau khi AI s·ª≠a, v·∫´n n√™n sanitize l·∫°i m·ªôt l·∫ßn n·ªØa ƒë·ªÉ ch·∫Øc ch·∫Øn
        repaired_str = sanitize_latex_json(repaired_str)
        
        return json.loads(repaired_str, strict=False)
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói JSON l·∫ßn 2 (AI Give up): {e}")
        return None
def generate_or_get_image(hinh_anh_data: Dict) -> tuple:
    """
    X·ª≠ l√Ω g·ªçi h√†m sinh ·∫£nh.
    Returns: (image_bytes, placeholder_text) - image_bytes l√† 1 object duy nh·∫•t
    """
    mo_ta = hinh_anh_data.get("mo_ta", hinh_anh_data.get("description", ""))
    mo_ta = str(mo_ta).strip()
    loai = hinh_anh_data.get("loai", "tu_mo_ta")
    
    if loai == "tu_mo_ta" and mo_ta:
        try:
            from modules.common.text2Image import generate_image_from_text
            # H√†m n√†y tr·∫£ v·ªÅ 1 bytes object (ho·∫∑c None)
            image_bytes = generate_image_from_text(mo_ta)
            if image_bytes:
                return image_bytes, None
            else:
                # N·∫øu API tr·∫£ v·ªÅ None (do l·ªói m·∫°ng ho·∫∑c quota)
                return None, f"‚ö†Ô∏è [L·ªói sinh ·∫£nh] Server kh√¥ng tr·∫£ v·ªÅ ·∫£nh cho m√¥ t·∫£: {mo_ta}"
        except Exception as e:
            print(f"‚ùå L·ªói sinh ·∫£nh: {e}")
            return None, f"‚ö†Ô∏è [L·ªói Code] {str(e)}"
    
    placeholder = f"üñºÔ∏è [C·∫ßn ch√®n h√¨nh: {mo_ta}]"
    return None, placeholder

def insert_image_or_placeholder(doc: Document, hinh_anh_data: Dict):
    """Ch√®n ·∫£nh ho·∫∑c placeholder v√†o document"""
    image_bytes, placeholder = generate_or_get_image(hinh_anh_data)
    
    if image_bytes:
        try:
            image_stream = BytesIO(image_bytes)
            doc.add_picture(image_stream, width=Inches(4))
            doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER
        except Exception as e:
            print(f"‚ùå L·ªói ch√®n ·∫£nh: {e}")
            p = doc.add_paragraph()
            run = p.add_run(f"‚ö†Ô∏è [L·ªói ch√®n ·∫£nh: {str(e)}]")
            run.font.color.rgb = RGBColor(255, 0, 0)
            run.italic = True
    
    elif placeholder:
        p = doc.add_paragraph()
        run = p.add_run(placeholder)
        run.font.color.rgb = RGBColor(200, 0, 0)
        run.italic = True
        run.bold = True
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    return doc

import json
from typing import Dict, List, Optional, Any

class PromptBuilder:
    """
    Builder t·∫°o prompt ƒë·ªông, t·ªëi ∆∞u ri√™ng cho KHOA H·ªåC X√É H·ªòI ƒë·ªÉ tr√°nh l·ªói LaTeX
    H·ªó tr·ª£: Tr·∫Øc nghi·ªám 4 ƒë√°p √°n, ƒê√∫ng/Sai, Tr·∫£ l·ªùi ng·∫Øn.
    """
    
    @staticmethod
    def build_json_structure_hint(question_type: str) -> str:
        """
        T·∫°o hint c·∫•u tr√∫c JSON cho c√°c lo·∫°i ƒë·ªÅ
        """
        if question_type == "trac_nghiem_4_dap_an":
            return """
{
  "loai_de": "trac_nghiem_4_dap_an",
  "tong_so_cau": 80,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "nhan_biet",
      "phan": "PH·∫¶N I: L·ªäCH S·ª¨ TH·∫æ GI·ªöI",
      "noi_dung": "N·ªôi dung c√¢u h·ªèi (Kh√¥ng d√πng d·∫•u $)...",
      "trich_dan": "ƒêo·∫°n vƒÉn b·∫£n g·ªëc t·ª´ PDF (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu, n·∫øu kh√¥ng ƒë·ªÉ chu·ªói r·ªóng \"\")",
      "nguon_trich_dan": "(SGK L·ªãch s·ª≠ 12, b·ªô C√°nh Di·ªÅu, trang 10) (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu)",
      "hinh_anh": {
        "co_hinh": true,
        "loai": "tu_mo_ta",
        "mo_ta": "M√¥ t·∫£ chi ti·∫øt h√¨nh ·∫£nh (B·∫£n ƒë·ªì/L∆∞·ª£c ƒë·ªì/Ch√¢n dung)..."
      },
      "dap_an": [
        {"ky_hieu": "A", "noi_dung": "N·ªôi dung ƒë√°p √°n A"},
        {"ky_hieu": "B", "noi_dung": "N·ªôi dung ƒë√°p √°n B"},
        {"ky_hieu": "C", "noi_dung": "N·ªôi dung ƒë√°p √°n C"},
        {"ky_hieu": "D", "noi_dung": "N·ªôi dung ƒë√°p √°n D"}
      ],
      "dap_an_dung": 2,
      "giai_thich": "Gi·∫£i th√≠ch chi ti·∫øt..."
    }
  ]
}
"""
        elif question_type == "dung_sai":
            return """
{
  "loai_de": "dung_sai",
  "tong_so_cau": 40,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "thong_hieu",
      "phan": "PH·∫¶N I",
      "doan_thong_tin": "ƒêo·∫°n t∆∞ li·ªáu ƒë·∫ßu b√†i...",
      "trich_dan": "Tr√≠ch d·∫´n nguy√™n vƒÉn t·ª´ PDF (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu, n·∫øu kh√¥ng ƒë·ªÉ chu·ªói r·ªóng \"\")",
      "nguon_trich_dan": "(Ngu·ªìn...) (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu)",
      "hinh_anh": { "co_hinh": false },
      "cac_y": [
        {"ky_hieu": "a", "noi_dung": "Ph√°t bi·ªÉu a", "dung": false},
        {"ky_hieu": "b", "noi_dung": "Ph√°t bi·ªÉu b", "dung": true},
        {"ky_hieu": "c", "noi_dung": "Ph√°t bi·ªÉu c", "dung": false},
        {"ky_hieu": "d", "noi_dung": "Ph√°t bi·ªÉu d", "dung": true}
      ],
      "dap_an_dung_sai": "0101",
      "giai_thich": [
        {"y": "a", "noi_dung_y": "...", "ket_luan": "SAI", "giai_thich": "Gi·∫£i th√≠ch..."},
        {"y": "b", "noi_dung_y": "...", "ket_luan": "ƒê√öNG", "giai_thich": "Gi·∫£i th√≠ch..."}
      ]
    }
  ]
}
"""
        elif question_type == "tra_loi_ngan":
            return """
{
  "loai_de": "tra_loi_ngan",
  "tong_so_cau": 30,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "nhan_biet",
      "phan": "PH·∫¶N I",
      "noi_dung": "N·ªôi dung c√¢u h·ªèi ng·∫Øn g·ªçn...",
      "trich_dan": "ƒêo·∫°n vƒÉn b·∫£n g·ªëc (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu, n·∫øu kh√¥ng ƒë·ªÉ chu·ªói r·ªóng \"\")",
      "nguon_trich_dan": "(Ngu·ªìn...) (ƒêi·ªÅn n·∫øu c√≥ t∆∞ li·ªáu)",
      "hinh_anh": {
        "co_hinh": true,
        "loai": "tu_mo_ta",
        "mo_ta": "M√¥ t·∫£ chi ti·∫øt h√¨nh ·∫£nh..."
      },
      "dap_an": "ƒê√°p √°n ng·∫Øn g·ªçn (Vd: 1945 ho·∫∑c H√† N·ªôi)",
      "giai_thich": "Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ ƒë√°p √°n..."
    }
  ]
}
"""
        return "{}"
    
    @staticmethod
    def wrap_user_prompt(user_prompt: str, question_type: str) -> str:
        json_hint = PromptBuilder.build_json_structure_hint(question_type)
        
        # PROMPT ƒê∆Ø·ª¢C T·ªêI ∆ØU RI√äNG CHO X√É H·ªòI (Ch·∫∑n LaTeX, Citations linh ho·∫°t)
        return f"""{user_prompt}

----------------
### H∆Ø·ªöNG D·∫™N K·ª∏ THU·∫¨T (SYSTEM INSTRUCTION) - B·∫ÆT BU·ªòC TU√ÇN TH·ª¶:

1. **QUY T·∫ÆC ƒê·ªäNH D·∫†NG VƒÇN B·∫¢N (KH·∫ÆC PH·ª§C L·ªñI LATEX - D√†nh cho S·ª≠/ƒê·ªãa):**
   - ƒê√¢y l√† m√¥n **KHOA H·ªåC X√É H·ªòI (L·ªãch S·ª≠ / ƒê·ªãa L√Ω)**.
   - **TUY·ªÜT ƒê·ªêI KH√îNG** s·ª≠ d·ª•ng d·∫•u `$` ho·∫∑c c·∫∑p d·∫•u `$$` trong n·ªôi dung JSON.
   - **X·ª≠ l√Ω To·∫° ƒë·ªô ƒê·ªãa l√Ω / ƒê·ªô C / Ph·∫ßn trƒÉm:**
     + SAI (C·∫•m): `$20^0N$`, `$105^0E$`, `$30^0C$`, `$25\%$`.
     + ƒê√öNG (B·∫Øt bu·ªôc): D√πng k√Ω t·ª± Unicode ho·∫∑c ch·ªØ th∆∞·ªùng.
       -> "20¬∞B", "105¬∞ƒê", "20 ƒë·ªô Vƒ© B·∫Øc", "30¬∞C", "25%".
   - **X·ª≠ l√Ω Ng√†y th√°ng / Th·∫ø k·ª∑:**
     + SAI: `$th·∫ø k·ª∑ XX$`, `$nƒÉm 1945$`.
     + ƒê√öNG: "th·∫ø k·ª∑ XX", "nƒÉm 1945".

2. **QUY T·∫ÆC TR√çCH D·∫™N T∆Ø LI·ªÜU (C·ª®NG NH∆ØNG LINH HO·∫†T):**
   - **Y√™u c·∫ßu B·∫ÆT BU·ªòC:** N·∫øu c√¢u h·ªèi **d·ª±a tr√™n ho·∫∑c tham chi·∫øu** ƒë·∫øn m·ªôt ƒëo·∫°n vƒÉn/t∆∞ li·ªáu c·ª• th·ªÉ (VD: C√¢u h·ªèi ƒë·ªçc hi·ªÉu trong L·ªãch s·ª≠, ho·∫∑c ph√¢n t√≠ch b·∫£ng s·ªë li·ªáu trong ƒê·ªãa l√Ω), b·∫°n **PH·∫¢I** ƒëi·ªÅn ƒë·∫ßy ƒë·ªß 2 tr∆∞·ªùng sau:
     + `"trich_dan"`: Copy nguy√™n vƒÉn ƒëo·∫°n text/t∆∞ li·ªáu t·ª´ PDF l√†m cƒÉn c·ª©.
     + `"nguon_trich_dan"`: Ghi r√µ ngu·ªìn g·ªëc (SGK..., trang...).
   - **Tr∆∞·ªùng h·ª£p MI·ªÑN TR·ª™:** N·∫øu c√¢u h·ªèi mang t√≠nh kh√°i qu√°t (VD: T√°c d·ª•ng c·ªßa gi√≥ m√πa, nƒÉm di·ªÖn ra s·ª± ki·ªán...) ho·∫∑c ch·ªâ d√πng h√¨nh ·∫£nh (B·∫£n ƒë·ªì) m√† kh√¥ng c·∫ßn tr√≠ch d·∫´n nguy√™n vƒÉn vƒÉn b·∫£n, h√£y ƒë·ªÉ **chu·ªói r·ªóng** `""` cho c·∫£ hai tr∆∞·ªùng n√†y.

3. **Y√äU C·∫¶U V·ªÄ H√åNH ·∫¢NH:**
   - N·∫øu n·ªôi dung li√™n quan ƒë·∫øn B·∫£n ƒë·ªì, L∆∞·ª£c ƒë·ªì, Bi·ªÉu ƒë·ªì... -> B·∫ÆT BU·ªòC ƒë·∫∑t `"co_hinh": true` v√† ƒëi·ªÅn m√¥ t·∫£ chi ti·∫øt v√†o `"mo_ta"`.

4. **FORMAT JSON OUTPUT:**
   - Ch·ªâ tr·∫£ v·ªÅ duy nh·∫•t 1 chu·ªói JSON.
   - Kh√¥ng ƒë∆∞·ª£c c√≥ text d·∫´n nh·∫≠p hay k·∫øt th√∫c.
   - ƒê·∫£m b·∫£o JSON valid.

### M·∫™U JSON MONG MU·ªêN:
{json_hint}
"""

# ============================================================================
# PH·∫¶N 5: DYNAMIC DOCX RENDERER (M·ªöI - AUTO-ADAPT)
# ============================================================================

class DynamicDocxRenderer:
    def __init__(self, doc: Document):
        self.doc = doc
    
    def render_title(self, data: Dict):
        """Render ti√™u ƒë·ªÅ t·ª± ƒë·ªông"""
        loai_de = data.get("loai_de", "").upper()
        title = self.doc.add_heading(f'ƒê·ªÄ {loai_de}', level=1)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    def auto_group_questions(self, data: Dict) -> Dict[str, List]:
        """
        T·ª± ƒë·ªông nh√≥m c√¢u h·ªèi v√† CHU·∫®N H√ìA key muc_do t·ª´ Ti·∫øng Vi·ªát sang code.
        Gi√∫p ng∆∞·ªùi d√πng tho·∫£i m√°i vi·∫øt prompt "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt"... m√† kh√¥ng b·ªã l·ªói file tr·∫Øng.
        """
        grouped = {}
        for cau in data.get("cau_hoi", []):
            # 1. L·∫•y d·ªØ li·ªáu th√¥ t·ª´ AI (v√≠ d·ª•: "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt", "Th√¥ng hi·ªÉu")
            # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ so s√°nh
            raw_muc_do = str(cau.get("muc_do", "unknown")).lower().strip()
            
            # 2. Logic "Phi√™n d·ªãch" th√¥ng minh (Mapping)
            # ∆Øu ti√™n check "cao" tr∆∞·ªõc ƒë·ªÉ ph√¢n bi·ªát "V·∫≠n d·ª•ng" v√† "V·∫≠n d·ª•ng cao"
            if "cao" in raw_muc_do:
                muc_do_chuan = "van_dung_cao"
            elif "d·ª•ng" in raw_muc_do or "dung" in raw_muc_do:
                muc_do_chuan = "van_dung"
            elif "th√¥ng" in raw_muc_do or "thong" in raw_muc_do:
                muc_do_chuan = "thong_hieu"
            elif "nh·∫≠n" in raw_muc_do or "nhan" in raw_muc_do:
                muc_do_chuan = "nhan_biet"
            else:
                # Tr∆∞·ªùng h·ª£p AI ghi n·ªôi dung l·∫°, m·∫∑c ƒë·ªãnh ƒë∆∞a v√†o V·∫≠n d·ª•ng 
                # ƒë·ªÉ ƒë·∫£m b·∫£o c√¢u h·ªèi v·∫´n hi·ªán ra trong file (tr√°nh l·ªói trang tr·∫Øng)
                muc_do_chuan = "van_dung" 
            
            # 3. Gom nh√≥m theo key chu·∫©n
            if muc_do_chuan not in grouped:
                grouped[muc_do_chuan] = []
            grouped[muc_do_chuan].append(cau)
        
        # S·∫Øp x·∫øp theo STT trong m·ªói nh√≥m
        for key in grouped:
            grouped[key].sort(key=lambda x: x.get("stt", 0))
        
        return grouped
    
    def get_section_title(self, muc_do: str) -> str:
        """
        T·∫°o ti√™u ƒë·ªÅ section d·ª±a tr√™n m·ª©c ƒë·ªô
        C√ì TH·ªÇ m·ªü r·ªông b·∫±ng config file
        """
        mapping = {
            "nhan_biet": "I. C√ÇU H·ªéI NH·∫¨N BI·∫æT",
            "thong_hieu": "II. C√ÇU H·ªéI TH√îNG HI·ªÇU",
            "van_dung": "III. C√ÇU H·ªéI V·∫¨N D·ª§NG",
            "van_dung_cao": "IV. C√ÇU H·ªéI V·∫¨N D·ª§NG CAO"
        }
        return mapping.get(muc_do, muc_do.upper())
    
    def render_question_trac_nghiem(self, cau: Dict):
        """Render c√¢u h·ªèi tr·∫Øc nghi·ªám 4 ƒë√°p √°n"""
        # C√¢u h·ªèi
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        process_text_with_latex(cau['noi_dung'], p)
        
        # H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # ƒê√°p √°n - TH√äM X·ª¨ L√ù LATEX
        for dap_an in cau.get("dap_an", []):
            p_da = self.doc.add_paragraph()
            run_ky_hieu = p_da.add_run(f"{dap_an['ky_hieu']}. ")
            process_text_with_latex(dap_an['noi_dung'], p_da) 
        
        # L·ªùi gi·∫£i
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        
        if "dap_an_dung" in cau:
            p_dung = self.doc.add_paragraph()
            p_dung.add_run(f"{cau['dap_an_dung']}").bold = True
            self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch - TH√äM X·ª¨ L√ù LATEX
        giai_thich = cau.get("giai_thich", "")
        for line in giai_thich.split("\n"):
            if line.strip():
                p_gt = self.doc.add_paragraph()
                process_text_with_latex(line.strip(), p_gt)  
        
        # K·∫øt lu·∫≠n - TH√äM X·ª¨ L√ù LATEX
        if "dap_an_dung" in cau:
            dap_an_num = cau['dap_an_dung']
            noi_dung_dap_an = cau['dap_an'][dap_an_num-1]['noi_dung']
            p_ket_luan = self.doc.add_paragraph()
            run = p_ket_luan.add_run("V·∫≠y ƒë√°p √°n ƒë√∫ng l√†: ")
            run.bold = True
            process_text_with_latex(noi_dung_dap_an, p_ket_luan, bold=True) 
    
    def render_question_dung_sai(self, cau: Dict):
        """Render c√¢u h·ªèi ƒë√∫ng/sai"""
        # S·ªë c√¢u
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}.").bold = True
        
        # ƒêo·∫°n th√¥ng tin - TH√äM X·ª¨ L√ù LATEX
        if cau.get("doan_thong_tin"):
            p_doan = self.doc.add_paragraph()
            process_text_with_latex(cau.get("doan_thong_tin", ""), p_doan)  
        
        # H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # C√°c √Ω a, b, c, d - TH√äM X·ª¨ L√ù LATEX
        for y in cau.get("cac_y", []):
            p_y = self.doc.add_paragraph()
            p_y.add_run(f"{y['ky_hieu']}) ")
            process_text_with_latex(y['noi_dung'], p_y)  
        
        # L·ªùi gi·∫£i
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        
        p_da = self.doc.add_paragraph()
        p_da.add_run(cau.get("dap_an_dung_sai", "")).bold = True
        self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch t·ª´ng √Ω - TH√äM X·ª¨ L√ù LATEX
        for gt in cau.get("giai_thich", []):
            p_gt = self.doc.add_paragraph()
            p_gt.add_run('+) "')
            process_text_with_latex(gt.get('noi_dung_y', ''), p_gt)  
            run_kl = p_gt.add_run(f'" - {gt.get("ket_luan", "SAI")}. ')
            run_kl.bold = True
            
            if gt.get('giai_thich'):
                # p_gt_detail = self.doc.add_paragraph()
                process_text_with_latex(gt.get('giai_thich', ''), p_gt)  
    
    def render_question_tra_loi_ngan(self, cau: Dict):
        """Render c√¢u h·ªèi tr·∫£ l·ªùi ng·∫Øn"""
        # C√¢u h·ªèi
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        p_noi_dung = self.doc.add_paragraph()
        process_text_with_latex(cau['noi_dung'], p_noi_dung)  
        
        # H√¨nh ·∫£nh (n·∫øu c√≥)
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # ƒê√°p √°n - TH√äM X·ª¨ L√ù LATEX
        p_da = self.doc.add_paragraph()
        run_label = p_da.add_run("ƒê√°p √°n: ")
        run_label.bold = True
        
        raw_ans = str(cau.get('dap_an', '')).strip()
        if raw_ans.startswith("[[") and raw_ans.endswith("]]"):
            final_ans = raw_ans
        else:
            final_ans = f"[[{raw_ans}]]"
        
        # X·ª¨ L√ù LATEX TRONG ƒê√ÅP √ÅN
        process_text_with_latex(final_ans, p_da, bold=True)  
        
        # L·ªùi gi·∫£i header
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch chi ti·∫øt - ƒê√É C√ì X·ª¨ L√ù LATEX
        giai_thich = cau.get("giai_thich", "")
        lines = giai_thich.replace('\\n', '\n').split('\n')
        
        for line in lines:
            text = line.strip()
            if not text or text == "####":
                continue
            
            is_bold = False
            if text.startswith("**") and text.endswith("**"):
                text = text[2:-2]
                is_bold = True
            
            check_text = text.replace('*', '').strip().lower()
            if check_text.startswith("v·∫≠y"):
                is_bold = True
                text = text.replace('**', '')

            p_gt = self.doc.add_paragraph()
            process_text_with_latex(text, p_gt, bold=is_bold)  
    
    def render_all(self, data: Dict):
        """
        Main render function - C√≥ h·ªó tr·ª£ chia PH·∫¶N (PART) b√™n trong M·ª©c ƒë·ªô
        """
        self.render_title(data)
        
        # 1. Auto-group theo m·ª©c ƒë·ªô (Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu...)
        grouped = self.auto_group_questions(data)
        
        # 2. Detect lo·∫°i ƒë·ªÅ
        loai_de = data.get("loai_de", "")
        
        # 3. Render t·ª´ng nh√≥m M·ª®C ƒê·ªò
        # Th·ª© t·ª± ∆∞u ti√™n render
        order_muc_do = ["nhan_biet", "thong_hieu", "van_dung", "van_dung_cao"]
        
        for muc_do in order_muc_do:
            if muc_do not in grouped:
                continue
            
            # L·∫•y danh s√°ch c√¢u h·ªèi trong m·ª©c ƒë·ªô n√†y
            questions = grouped[muc_do]
            if not questions:
                continue
            section_title = self.get_section_title(muc_do)
            self.doc.add_heading(section_title, level=2)
            current_phan = None

            for cau in questions:
                # L·∫•y t√™n ph·∫ßn c·ªßa c√¢u hi·ªán t·∫°i
                phan_cua_cau = str(cau.get("phan", "")).strip()
                
                # N·∫øu c√¢u n√†y thu·ªôc m·ªôt ph·∫ßn m·ªõi -> In Header Ph·∫ßn
                if phan_cua_cau and phan_cua_cau != current_phan:
                    # In ra header c·∫•p 3 (VD: Ph·∫ßn 1: ƒê·ªôi ng≈©...)
                    # D√πng m√†u ho·∫∑c in ƒë·∫≠m ƒë·ªÉ ph√¢n bi·ªát
                    p_phan = self.doc.add_heading(phan_cua_cau.upper(), level=3)
                    p_phan.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    current_phan = phan_cua_cau
                
                # Render n·ªôi dung c√¢u h·ªèi nh∆∞ b√¨nh th∆∞·ªùng
                if loai_de == "dung_sai":
                    self.render_question_dung_sai(cau)
                elif loai_de == "tra_loi_ngan":
                    self.render_question_tra_loi_ngan(cau)
                else:
                    self.render_question_trac_nghiem(cau)

def response2docx_flexible(
    file_path: str,
    prompt: str,
    file_name: str,
    project_id: str,
    creds: str,
    model_name: str,
    question_type: str = "trac_nghiem_4_dap_an",
    batch_name: Optional[str] = None
) -> Optional[str]:
    try:
        from modules.common.callAPI import VertexClient
        
        client = VertexClient(project_id, creds, model_name)
        
        if not batch_name:
            batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
        
        # 1. Wrap prompt v·ªõi JSON structure hint
        final_prompt = PromptBuilder.wrap_user_prompt(prompt, question_type)
        
        # 2. G·ª≠i request AI
        print("üì§ ƒêang g·ª≠i request t·ªõi AI...")
        ai_response = client.send_data_to_AI(final_prompt, file_path)
        
        # 3. Parse JSON
        print("üîÑ ƒêang parse JSON...")
        data = parse_json_safely(ai_response, client)
        if not data:
            print("‚ùå Kh√¥ng th·ªÉ parse JSON t·ª´ AI")
            return None
        
        print(f"‚úÖ Parse th√†nh c√¥ng: {data.get('tong_so_cau', 0)} c√¢u h·ªèi")
        
        # 4. Render DOCX ƒë·ªông
        print("üìù ƒêang t·∫°o DOCX...")
        doc = Document()
        renderer = DynamicDocxRenderer(doc)
        
        try:
            renderer.render_all(data)
            print("‚úÖ Render DOCX th√†nh c√¥ng")
        except Exception as e:
            print(f"‚ùå L·ªói khi render DOCX: {e}")
            traceback.print_exc()
            return None
        
        # 5. L∆∞u file
        print("üíæ ƒêang l∆∞u file...")
        output_path = save_document_securely(doc, batch_name, file_name)
        
        if output_path:
            print(f"‚úÖ Ho√†n th√†nh: {output_path}")
        else:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u file")
            
        return output_path
    
    except Exception as e:
        print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG: {e}")
        traceback.print_exc()
        return None

def response2docx_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫Øc nghi·ªám 4 ƒë√°p √°n (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="trac_nghiem_4_dap_an",
        batch_name=batch_name
    )

def response2docx_dung_sai_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho ƒë√∫ng/sai (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="dung_sai",
        batch_name=batch_name
    )
    
def response2docx_tra_loi_ngan_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫£ l·ªùi ng·∫Øn (legacy compatibility)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="tra_loi_ngan",
        batch_name=batch_name
    )

class ConfigManager:
    """
    Qu·∫£n l√Ω c·∫•u h√¨nh qua file JSON
    Cho ph√©p thay ƒë·ªïi TO√ÄN B·ªò behavior m√† kh√¥ng s·ª≠a code
    """
    
    DEFAULT_CONFIG = {
        "section_mapping": {
            "nhan_biet": "I. C√ÇU H·ªéI NH·∫¨N BI·∫æT",
            "thong_hieu": "II. C√ÇU H·ªéI TH√îNG HI·ªÇU",
            "van_dung": "III. C√ÇU H·ªéI V·∫¨N D·ª§NG",
            "van_dung_cao": "IV. C√ÇU H·ªéI V·∫¨N D·ª§NG CAO" 
        },
        "section_order": ["nhan_biet", "thong_hieu", "van_dung", "van_dung_cao"],
        "auto_fix": True,
        "image_width_inches": 4,
        "retry_json_parse": 2
    }
    
    @classmethod
    def load_config(cls, config_path: str = "config.json") -> Dict:
        """Load config t·ª´ file ho·∫∑c d√πng default"""
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return cls.DEFAULT_CONFIG
    
    @classmethod
    def save_config(cls, config: Dict, config_path: str = "config.json"):
        """L∆∞u config ƒë·ªÉ t√°i s·ª≠ d·ª•ng"""
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

