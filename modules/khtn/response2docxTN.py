import json
import os
import sys
import threading
import time
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
from typing import Dict, List, Optional, Any
import zipfile
import subprocess
import re
from tempfile import NamedTemporaryFile
from docx.oxml import parse_xml
import traceback
from modules.common.schema import (
    schema_trac_nghiem, 
    schema_dung_sai, 
    schema_tra_loi_ngan, 
    schema_tu_luan
)

_FILE_LOCK = threading.RLock()
_OUTPUT_DIR_LOCK = threading.RLock()

def get_app_path():
    """L·∫•y ƒë∆∞·ªùng d·∫´n ch·ª©a file .exe ho·∫∑c script"""
    if getattr(sys, 'frozen', False):
        return os.path.dirname(sys.executable)
    return os.path.dirname(os.path.abspath(__file__))
def sanitize_xml_string(text):
    """
    Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒëi·ªÅu khi·ªÉn kh√¥ng h·ª£p l·ªá trong XML (ASCII 0-31, tr·ª´ 9, 10, 13).
    """
    if not text:
        return ""
    # Regex lo·∫°i b·ªè c√°c k√Ω t·ª± t·ª´ \x00-\x08, \x0B-\x0C, \x0E-\x1F
    return re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F]', '', str(text))
def find_pandoc_executable():
    """
    T√¨m pandoc.exe theo th·ª© t·ª± ∆∞u ti√™n:
    1. Th∆∞ m·ª•c 'pandoc' c·∫°nh tool (cho b·∫£n build)
    2. PATH h·ªá th·ªëng (cho m√¥i tr∆∞·ªùng dev)
    """
    app_path = get_app_path()
    
    # 1. T√¨m trong th∆∞ m·ª•c c·ª•c b·ªô 'pandoc' (∆∞u ti√™n cao nh·∫•t)
    local_pandoc = os.path.join(app_path, 'pandoc', 'pandoc.exe')
    if os.path.isfile(local_pandoc):
        # print(f"‚úÖ S·ª≠ d·ª•ng Pandoc c·ª•c b·ªô: {local_pandoc}")
        return local_pandoc
    
    # 2. Fallback: T√¨m trong PATH h·ªá th·ªëng (cho dev)
    import shutil
    system_pandoc = shutil.which('pandoc')
    if system_pandoc:
        # print(f"‚ö†Ô∏è S·ª≠ d·ª•ng Pandoc h·ªá th·ªëng: {system_pandoc}")
        return system_pandoc
    
    # 3. Kh√¥ng t√¨m th·∫•y
    print("‚ùå KH√îNG T√åM TH·∫§Y PANDOC!")
    return None

def latex_to_omml_via_pandoc(latex_math_dollar):
    """Chuy·ªÉn ƒë·ªïi LaTeX sang OMML qua Pandoc"""
    pandoc_exe = find_pandoc_executable()
    
    if not pandoc_exe:
        print("‚ùå Pandoc kh√¥ng kh·∫£ d·ª•ng, b·ªè qua equation")
        return None
    
    try:
        # Chu·∫©n h√≥a input (lo·∫°i b·ªè k√Ω t·ª± l·∫°)
        latex_clean = latex_math_dollar.strip()
        
        # T·∫°o file t·∫°m v·ªõi encoding UTF-8 BOM ƒë·ªÉ tr√°nh l·ªói
        with NamedTemporaryFile(mode='w', suffix=".docx", delete=False, encoding='utf-8') as temp_docx:
            temp_path = temp_docx.name
        
        # Ch·∫°y Pandoc v·ªõi error handling t·ªët h∆°n
        result = subprocess.run(
            [pandoc_exe, '--from=latex', '--to=docx', '-o', temp_path],
            input=latex_clean,
            text=True,
            encoding='utf-8',
            capture_output=True,
            timeout=10,  # Timeout 10s ƒë·ªÉ tr√°nh treo
            creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
        )
 
        if result.returncode != 0:
            error_msg = result.stderr.strip() if result.stderr else "Unknown error"
            # print(f"‚ö†Ô∏è Pandoc error (code {result.returncode}): {error_msg}")
            
            # Ki·ªÉm tra l·ªói ph·ªï bi·∫øn
            if "not found" in error_msg.lower() or "cannot find" in error_msg.lower():
                print("   ‚Üí Thi·∫øu DLL dependencies. Ki·ªÉm tra l·∫°i folder pandoc/")
            elif "syntax" in error_msg.lower():
                print(f"   ‚Üí LaTeX syntax error: {latex_clean[:50]}...")
            
            return None
        
        # Ki·ªÉm tra file output c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(temp_path) or os.path.getsize(temp_path) == 0:
            # print(f"‚ö†Ô∏è Pandoc kh√¥ng t·∫°o file output h·ª£p l·ªá")
            return None
           
        # ƒê·ªçc XML t·ª´ DOCX
        with zipfile.ZipFile(temp_path, 'r') as z:
            xml_content = z.read('word/document.xml').decode('utf-8')
        
        # D·ªçn d·∫πp file t·∫°m
        try:
            os.remove(temp_path)
        except:
            pass
       
        # T√¨m equation XML
        match = re.search(r'(<m:oMath[^>]*>.*?</m:oMath>)', xml_content, re.DOTALL)
        
        if not match:
            # print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y equation trong output: {latex_clean[:30]}...")
            return None
            
        return match.group(1)
   
    except subprocess.TimeoutExpired:
        print(f"‚ö†Ô∏è Pandoc timeout (>10s)")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói latex_to_omml: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None



def process_text_with_latex(text, paragraph, bold=False):
    """
    X·ª≠ l√Ω text c√≥ c√¥ng th·ª©c LaTeX
    VERSION ·ªîN ƒê·ªäNH - Copy t·ª´ test_res.py (KH√îNG c√≥ repair_broken_latex)
    """
    if not text:
        return
    text = sanitize_xml_string(text).strip()
    is_entirely_bold = bold
    if text.startswith("**") and text.endswith("**"):
        is_entirely_bold = True
        text = text[2:-2]
    # L√†m s·∫°ch HTML tags
    text = text.replace("<br>", "\n").replace("<br/>", "\n") \
               .replace("<Br>", "\n").replace("<Br/>", "\n")
    text = re.sub(r'</?(div|p|u|span|font|i|b)\b[^>]*>', '', text)
    text = text.replace("&nbsp;", "").replace("&lt;", "").replace("&gt;", "")
    
    # T√°ch text v√† LaTeX
    pattern = r'(\$[^$]+\$|\\\[.*?\\\])'
    parts = re.split(pattern, text)
    
    for part in parts:
        if not part:
            continue
        
        # Ph·∫ßn LaTeX
        if part.startswith('$') or part.startswith('\\['):
            try:
                latex_expr = clean_latex_math(part)
                insert_equation_into_paragraph(latex_expr, paragraph)
            except Exception as e:
                # Fallback: th√™m text thu·∫ßn
                run = paragraph.add_run(part)
                run.bold = is_entirely_bold
        # Ph·∫ßn text th∆∞·ªùng
        else:
            # cleaned_part = re.sub(r'^\s*/', '', part)
            # run = paragraph.add_run(cleaned_part)
            # if bold:
            #     run.bold = True
            sub_parts = re.split(r'(\*\*.*?\*\*)', part)
            for sp in sub_parts:
                sp_clean = sanitize_xml_string(sp)
                if not sp_clean: 
                    continue
                if sp.startswith("**") and sp.endswith("**"):
                    run = paragraph.add_run(sp[2:-2])
                    run.bold = True
                else:
                    run = paragraph.add_run(sp)
                    run.bold = is_entirely_bold


def insert_equation_into_paragraph(latex_math_dollar, paragraph):
    """Ch√®n c√¥ng th·ª©c to√°n h·ªçc v√†o paragraph"""
    omml_str = latex_to_omml_via_pandoc(latex_math_dollar)
    
    if not omml_str:
        # Fallback: Th√™m text thu·∫ßn n·∫øu kh√¥ng convert ƒë∆∞·ª£c
        paragraph.add_run(f" [{latex_math_dollar}] ")
        return
    
    # Th√™m namespace n·∫øu thi·∫øu
    if 'xmlns:m=' not in omml_str:
        omml_str = re.sub(
            r'<m:oMath',
            r'<m:oMath xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"',
            omml_str,
            count=1
        )
    
    try:
        omml_element = parse_xml(omml_str)
        run = paragraph.add_run()
        run._r.append(omml_element)
    except Exception as e:
        print(f"L·ªói ch√®n equation: {e}")
        paragraph.add_run(f" [{latex_math_dollar}] ")


def clean_latex_math(latex_raw):
    latex_raw = latex_raw.lstrip('$').rstrip('$')
    latex_raw = latex_raw.strip()
    latex_raw = re.sub(r'\\/', '', latex_raw)
    latex_raw = re.sub(r'\\operatorname\s*{\s*([^}]*)\s*}',
                       lambda m: m.group(1).replace(' ', ''), latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*{(\d+)}\s*\\of\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*\\sqrt\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'([a-zA-Z])\s*\\frac\s*{([^}]+)}\s*{([^}]+)}',
                       r'\1^{\\frac{\2}{\3}}', latex_raw)
    latex_raw = re.sub(r'\\sp\s*{([^}]*)}', r'^{\1}', latex_raw)
    latex_raw = re.sub(r'{\\bf\s*([^}]*)}', r'\1', latex_raw)
    latex_raw = re.sub(r'\\\s*log', r'\\log', latex_raw)
    latex_raw = re.sub(r'\\bigskip', '', latex_raw)
    latex_raw = re.sub(r'\\nonumber', '', latex_raw)
    latex_raw = latex_raw.replace(r'\?', '?')
    latex_raw = re.sub(r'\\cdot\s*(?=\w)', r'\\cdot ', latex_raw)
    latex_raw = latex_raw.replace(r'\dotstan', r'\cdot \tan')
    latex_raw = re.sub(r'(?<!\\)(\bln\b|\blog\b|\bsin\b|\bcos\b|\btan\b|\blog_{?\d*}?)',
                       r'\\\1', latex_raw)
    latex_raw = re.sub(r'(\\Leftrightarrow|\\Rightarrow|\\rightarrow)(?=\w)', r'\1 ', latex_raw)
    latex_raw = latex_raw.replace(r'\\n', r'\n')
    
    latex_raw = latex_raw.strip()
    # ‚úÖ KH√ÅC BI·ªÜT: Version c≈© KH√îNG replace \n v√† \r
    # latex_raw = latex_raw.replace('\n', ' ').replace('\r', '')  # ‚Üê X√ìA D√íNG N√ÄY
    
    if not (latex_raw.startswith('$') and latex_raw.endswith('$')):
        latex_raw = f"${latex_raw}$"
    
    return latex_raw

def ensure_output_folder_for_batch(batch_name):
    """T·∫°o folder ri√™ng cho batch"""
    base_path = get_app_path()
    output_base = os.path.join(base_path, "output")
    batch_folder = os.path.join(output_base, batch_name)
    
    with _OUTPUT_DIR_LOCK:
        os.makedirs(output_base, exist_ok=True)
        os.makedirs(batch_folder, exist_ok=True)
    
    return batch_folder

def save_document_securely(doc, batch_name, file_name):
    """L∆∞u file DOCX v·ªõi thread-safety"""
    batch_folder = ensure_output_folder_for_batch(batch_name)
    if not batch_folder:
        return None

    output_path = os.path.join(batch_folder, f"{file_name}.docx")
    
    with _FILE_LOCK:
        max_retries = 3
        for retry_count in range(max_retries):
            try:
                doc.save(output_path)
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    print(f"‚úÖ ƒê√£ l∆∞u file: {output_path}")
                    return output_path
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói l∆∞u file l·∫ßn {retry_count + 1}: {e}")
                if retry_count < max_retries - 1:
                    time.sleep(1)
        
        print(f"‚ùå Kh√¥ng th·ªÉ l∆∞u file sau {max_retries} l·∫ßn th·ª≠")
        return None
def save_json_securely(data, batch_name, file_name):
    """L∆∞u file JSON v·ªõi thread-safety"""
    batch_folder = ensure_output_folder_for_batch(batch_name)
    if not batch_folder: return None

    output_path = os.path.join(batch_folder, f"{file_name}.json")
    with _FILE_LOCK:
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ ƒê√£ l∆∞u file JSON: {output_path}")
            return output_path
        except Exception as e:
            print(f"‚ùå L·ªói l∆∞u file JSON: {e}")
            return None
def generate_or_get_image(hinh_anh_data: Dict) -> tuple:
    mo_ta = hinh_anh_data.get("mo_ta", hinh_anh_data.get("description", ""))
    mo_ta = str(mo_ta).strip()
    loai = hinh_anh_data.get("loai", "tu_mo_ta")
    
    if loai == "tu_mo_ta" and mo_ta:
        try:
            from modules.common.text2Image import generate_image_from_text
            # H√†m n√†y tr·∫£ v·ªÅ 1 bytes object (ho·∫∑c None)
            image_bytes = generate_image_from_text(mo_ta)
            if image_bytes:
                return image_bytes, None
            else:
                # N·∫øu API tr·∫£ v·ªÅ None (do l·ªói m·∫°ng ho·∫∑c quota)
                return None, f"‚ö†Ô∏è [L·ªói sinh ·∫£nh] Server kh√¥ng tr·∫£ v·ªÅ ·∫£nh cho m√¥ t·∫£: {mo_ta}"
        except Exception as e:
            print(f"‚ùå L·ªói sinh ·∫£nh: {e}")
            return None, f"‚ö†Ô∏è [L·ªói Code] {str(e)}"
    
    placeholder = f"üñºÔ∏è [C·∫ßn ch√®n h√¨nh: {mo_ta}]"
    return None, placeholder

def insert_image_or_placeholder(doc: Document, hinh_anh_data: Dict):
    """Ch√®n ·∫£nh ho·∫∑c placeholder v√†o document"""
    image_bytes, placeholder = generate_or_get_image(hinh_anh_data)
    
    if image_bytes:
        try:
            image_stream = BytesIO(image_bytes)
            doc.add_picture(image_stream, width=Inches(4))
            doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER
        except Exception as e:
            print(f"‚ùå L·ªói ch√®n ·∫£nh: {e}")
            p = doc.add_paragraph()
            run = p.add_run(f"‚ö†Ô∏è [L·ªói ch√®n ·∫£nh: {str(e)}]")
            run.font.color.rgb = RGBColor(255, 0, 0)
            run.italic = True
    
    elif placeholder:
        p = doc.add_paragraph()
        run = p.add_run(placeholder)
        run.font.color.rgb = RGBColor(200, 0, 0)
        run.italic = True
        run.bold = True
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    return doc

class PromptBuilder:
    """
    PromptBuilder m·ªõi: G·ªçn nh·∫π, ch·ªâ t·∫≠p trung v√†o n·ªôi dung.
    Kh√¥ng c√≤n nh·ªìi nh√©t c·∫•u tr√∫c JSON v√†o prompt.
    """
    @staticmethod
    def wrap_user_prompt(user_prompt: str) -> str:
        # Ch·ªâ gi·ªØ l·∫°i c√°c quy t·∫Øc c·ªët l√µi v·ªÅ n·ªôi dung
        return f"""{user_prompt}

----------------
### Y√äU C·∫¶U K·ª∏ THU·∫¨T QUAN TR·ªåNG:

1. **TU√ÇN TH·ª¶ SCHEMA:**
   - Output tr·∫£ v·ªÅ PH·∫¢I kh·ªõp ch√≠nh x√°c v·ªõi c·∫•u tr√∫c JSON Schema ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong h·ªá th·ªëng.
   - Tuy·ªát ƒë·ªëi kh√¥ng th√™m l·ªùi d·∫´n, kh√¥ng th√™m markdown (```json). Ch·ªâ tr·∫£ v·ªÅ Raw JSON.

2. **QUY T·∫ÆC LATEX (B·∫ÆT BU·ªòC):**
   - M·ªçi c√¥ng th·ª©c To√°n/L√Ω/H√≥a ph·∫£i ƒë·∫∑t trong d·∫•u `$`.
   - V√≠ d·ª•: $x^2 + 2x$, $H_2SO_4$.
   - **L∆∞u √Ω escape:** Trong chu·ªói JSON, k√Ω t·ª± backslash `\\` ph·∫£i ƒë∆∞·ª£c nh√¢n ƒë√¥i th√†nh `\\\\`. 
     V√≠ d·ª•: mu·ªën vi·∫øt $\\frac{{1}}{{2}}$ th√¨ trong JSON ph·∫£i l√† "$\\\\frac{{1}}{{2}}$".

3. **H√åNH ·∫¢NH:**
   - Lu√¥n ƒëi·ªÅn tr∆∞·ªùng "mo_ta" chi ti·∫øt n·∫øu c√¢u h·ªèi c·∫ßn h√¨nh minh h·ªça (ƒë·ªì th·ªã, th√≠ nghi·ªám, b·∫£n ƒë·ªì...).
"""

def get_schema_by_type(question_type: str):
    """Mapping lo·∫°i c√¢u h·ªèi sang Schema object"""
    mapping = {
        "trac_nghiem_4_dap_an": schema_trac_nghiem,
        "dung_sai": schema_dung_sai,
        "tra_loi_ngan": schema_tra_loi_ngan,
        "tu_luan": schema_tu_luan
    }
    return mapping.get(question_type, schema_trac_nghiem)
class DynamicDocxRenderer:
    """
    Renderer t·ª± ƒë·ªông th√≠ch ·ª©ng v·ªõi c·∫•u tr√∫c JSON
    """
    
    def __init__(self, doc: Document):
        self.doc = doc
    
    def render_title(self, data: Dict):
        """Render ti√™u ƒë·ªÅ t·ª± ƒë·ªông"""
        loai_de = data.get("loai_de", "").upper()
        title = self.doc.add_heading(f'ƒê·ªÄ {loai_de}', level=1)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        ma_bai = data.get("ma_bai", "")
        if ma_bai:
            p_ma_bai = self.doc.add_paragraph()
            p_ma_bai.add_run(f"[{ma_bai},,]")
    def render_ma_dang_header(self, ma_dang: str):
        """Hi·ªÉn th·ªã [ma_dang] tr√™n m·ªôt d√≤ng ri√™ng bi·ªát"""
        if ma_dang:
            p_ma = self.doc.add_paragraph()
            p_ma.add_run(f"[{ma_dang},,]")
    def auto_group_questions(self, data: Dict) -> Dict[str, List]:
        """
        T·ª± ƒë·ªông nh√≥m c√¢u h·ªèi v√† CHU·∫®N H√ìA key muc_do t·ª´ Ti·∫øng Vi·ªát sang code.
        Gi√∫p ng∆∞·ªùi d√πng tho·∫£i m√°i vi·∫øt prompt "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt"... m√† kh√¥ng b·ªã l·ªói file tr·∫Øng.
        """
        grouped = {}
        for cau in data.get("cau_hoi", []):
            # 1. L·∫•y d·ªØ li·ªáu th√¥ t·ª´ AI (v√≠ d·ª•: "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt", "Th√¥ng hi·ªÉu")
            # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ so s√°nh
            raw_muc_do = str(cau.get("muc_do", "unknown")).lower().strip()
            
            # 2. Logic "Phi√™n d·ªãch" th√¥ng minh (Mapping)
            # ∆Øu ti√™n check "cao" tr∆∞·ªõc ƒë·ªÉ ph√¢n bi·ªát "V·∫≠n d·ª•ng" v√† "V·∫≠n d·ª•ng cao"
            if "cao" in raw_muc_do:
                muc_do_chuan = "van_dung_cao"
            elif "d·ª•ng" in raw_muc_do or "dung" in raw_muc_do:
                muc_do_chuan = "van_dung"
            elif "th√¥ng" in raw_muc_do or "thong" in raw_muc_do:
                muc_do_chuan = "thong_hieu"
            elif "nh·∫≠n" in raw_muc_do or "nhan" in raw_muc_do:
                muc_do_chuan = "nhan_biet"
            else:
                # Tr∆∞·ªùng h·ª£p AI ghi n·ªôi dung l·∫°, m·∫∑c ƒë·ªãnh ƒë∆∞a v√†o V·∫≠n d·ª•ng 
                # ƒë·ªÉ ƒë·∫£m b·∫£o c√¢u h·ªèi v·∫´n hi·ªán ra trong file (tr√°nh l·ªói trang tr·∫Øng)
                muc_do_chuan = "van_dung" 
            
            # 3. Gom nh√≥m theo key chu·∫©n
            if muc_do_chuan not in grouped:
                grouped[muc_do_chuan] = []
            grouped[muc_do_chuan].append(cau)
        
        # S·∫Øp x·∫øp theo STT trong m·ªói nh√≥m
        for key in grouped:
            grouped[key].sort(key=lambda x: x.get("stt", 0))
        
        return grouped
    
    def get_section_title(self, muc_do: str) -> str:
        """
        T·∫°o ti√™u ƒë·ªÅ section d·ª±a tr√™n m·ª©c ƒë·ªô
        C√ì TH·ªÇ m·ªü r·ªông b·∫±ng config file
        """
        mapping = {
            "nhan_biet": "I. C√ÇU H·ªéI NH·∫¨N BI·∫æT",
            "thong_hieu": "II. C√ÇU H·ªéI TH√îNG HI·ªÇU",
            "van_dung": "III. C√ÇU H·ªéI V·∫¨N D·ª§NG",
            "van_dung_cao": "IV. C√ÇU H·ªéI V·∫¨N D·ª§NG CAO"
        }
        return mapping.get(muc_do, muc_do.upper())
    
    def render_question_trac_nghiem(self, cau: Dict):
        self.render_ma_dang_header(cau.get("ma_dang"))
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        process_text_with_latex(cau.get('noi_dung', ''), p)
        
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        for dap_an in cau.get("cac_lua_chon", []):
            p_da = self.doc.add_paragraph()
            p_da.add_run(f"{dap_an['ky_hieu']}. ").bold = True
            process_text_with_latex(dap_an.get('noi_dung', ''), p_da)

        if cau.get('noi_dung_en'):
            self.doc.add_paragraph("(translate_en)").italic = True
            p_en = self.doc.add_paragraph()
            process_text_with_latex(cau.get('noi_dung_en', ''), p_en)
            
            for dap_an in cau.get("cac_lua_chon", []):
                p_da_en = self.doc.add_paragraph()
                p_da_en.add_run(f"{dap_an['ky_hieu']}. ").bold = True
                content_en = dap_an.get('noi_dung_en') or dap_an.get('noi_dung', '')
                process_text_with_latex(content_en, p_da_en)

        # --- PH·∫¶N 2: L·ªúI GI·∫¢I CHI TI·∫æT ---
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True # <-- Header v·∫´n in ƒë·∫≠m
        
        if "dap_an_dung" in cau:
            p_dung = self.doc.add_paragraph()
            p_dung.add_run(f"{cau['dap_an_dung']}").bold = True
            self.doc.add_paragraph("####") 

        # H√†m render t·ª´ng d√≤ng gi·∫£i th√≠ch
        def render_explanation_lines(text_block, lang='vi'):
            if not text_block: return
            
            lines = text_block.split("\n")
            for line in lines:
                text = line.strip()
                if not text: continue
                
                p_gt = self.doc.add_paragraph()
                
                # --- LOGIC M·ªöI: CH·ªà IN ƒê·∫¨M K·∫æT LU·∫¨N ---
                is_bold = False
                text_lower = text.lower()
                
                if lang == 'vi':
                    # Ch·ªâ in ƒë·∫≠m d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng "V·∫≠y..."
                    if text_lower.startswith("v·∫≠y ƒë√°p √°n") or text_lower.startswith("v·∫≠y, ƒë√°p √°n"):
                        is_bold = True
                else: # English
                    # Ch·ªâ in ƒë·∫≠m d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng "Therefore..."
                    if text_lower.startswith("therefore"):
                        is_bold = True
                
                process_text_with_latex(text, p_gt, bold=is_bold)

        # 2.1 Gi·∫£i th√≠ch Ti·∫øng Vi·ªát
        render_explanation_lines(cau.get("giai_thich", ""), lang='vi')

        # 2.2 Gi·∫£i th√≠ch Ti·∫øng Anh
        if cau.get("giai_thich_en"):
            self.doc.add_paragraph("(translate_en)").italic = True
            render_explanation_lines(cau.get("giai_thich_en", ""), lang='en')

        # --- PH·∫¶N 3: G·ª¢I √ù (Gi·ªØ nguy√™n) ---
        goi_y_vi = cau.get("goi_y", "")
        goi_y_en = cau.get("goi_y_en", "")
        
        if goi_y_vi or goi_y_en:
            self.doc.add_paragraph("####")
            if goi_y_vi:
                p_title = self.doc.add_paragraph()
                p_title.add_run("G·ª£i √Ω:").bold = True
                for line in goi_y_vi.split("\n"):
                    if not line.startswith("G·ª£i √Ω"):
                        process_text_with_latex(line.strip(), self.doc.add_paragraph())
            
            if goi_y_en:
                self.doc.add_paragraph("(translate_en)").italic = True
                p_title_en = self.doc.add_paragraph()
                p_title_en.add_run("Hint:").bold = True
                for line in goi_y_en.split("\n"):
                    if not line.startswith("Hint"):
                        process_text_with_latex(line.strip(), self.doc.add_paragraph())

    def render_question_dung_sai(self, cau: Dict):
        """
        Render c√¢u h·ªèi ƒê√∫ng/Sai v·ªõi GI·∫¢I TH√çCH D·∫†NG M·∫¢NG ƒê·ªêI T∆Ø·ª¢NG
        """
        # 1. Render Header c√¢u h·ªèi
        self.render_ma_dang_header(cau.get("ma_dang"))
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
       
        # 2. Render ƒêo·∫°n th√¥ng tin ng·ªØ c·∫£nh
        if cau.get("doan_thong_tin"):
            process_text_with_latex(cau.get("doan_thong_tin", ""), p)
       
        # 3. Render H√¨nh ·∫£nh (n·∫øu c√≥)
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
       
        # 4. Render c√°c √Ω a, b, c, d
        for y in cau.get("cac_y", []):
            p_y = self.doc.add_paragraph()
            p_y.add_run(f"{y['ky_hieu']}) ")
            process_text_with_latex(y.get('noi_dung', ''), p_y)
 
        # 5. Render Ti·∫øng Anh (n·∫øu c√≥)
        has_en = cau.get("doan_thong_tin_en") or any(y.get('noi_dung_en') for y in cau.get("cac_y", []))
        if has_en:
            self.doc.add_paragraph("(translate_en)").italic = True
            if cau.get("doan_thong_tin_en"):
                p_en = self.doc.add_paragraph()
                process_text_with_latex(cau.get("doan_thong_tin_en", ""), p_en)
           
            for y in cau.get("cac_y", []):
                p_y_en = self.doc.add_paragraph()
                p_y_en.add_run(f"{y['ky_hieu']}) ")
                content_en = y.get('noi_dung_en') or y.get('noi_dung', '')
                process_text_with_latex(content_en, p_y_en)
 
        # --- PH·∫¶N L·ªúI GI·∫¢I (C·∫¨P NH·∫¨T: X·ª¨ L√ù M·∫¢NG ƒê·ªêI T∆Ø·ª¢NG) ---
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
       
        # 6. ƒê√°p √°n bit (VD: 1001)
        p_da = self.doc.add_paragraph()
        p_da.add_run(str(cau.get("dap_an_dung_sai", ""))).bold = True
        self.doc.add_paragraph("####")
 
        # 7. Render Gi·∫£i th√≠ch Ti·∫øng Vi·ªát (M·∫¢NG ƒê·ªêI T∆Ø·ª¢NG)
        giai_thich_arr = cau.get("giai_thich", [])
        if isinstance(giai_thich_arr, list):
            for item in giai_thich_arr:
                # D√≤ng ti√™u ƒë·ªÅ: + (a.) N·ªôi dung √Ω. K·∫æT LU·∫¨N
                p_title = self.doc.add_paragraph()
               
                # Ph·∫ßn prefix: + (a.)
                prefix_run = p_title.add_run(f"+ ({item.get('ky_hieu', '').upper()}.) ")
                prefix_run.bold = False
               
                # L·∫•y n·ªôi dung √Ω t·ª´ cac_y ƒë·ªÉ hi·ªÉn th·ªã
                ky_hieu_curr = item.get('ky_hieu', '')
                noi_dung_y = ""
                for y in cau.get("cac_y", []):
                    if y.get('ky_hieu') == ky_hieu_curr:
                        noi_dung_y = y.get('noi_dung', '')
                        break
               
                # Th√™m n·ªôi dung √Ω
                if noi_dung_y:
                    process_text_with_latex(noi_dung_y, p_title, bold=False)
                    p_title.add_run(" ")
               
                # Th√™m k·∫øt lu·∫≠n (IN ƒê·∫¨M)
                ket_luan_run = p_title.add_run(item.get('ket_luan', ''))
                ket_luan_run.bold = True
               
                # Gi·∫£i th√≠ch chi ti·∫øt (d√≤ng ti·∫øp theo)
                p_detail = self.doc.add_paragraph()
                process_text_with_latex(item.get('noi_dung', ''), p_detail, bold=False)
 
        # 8. Render Gi·∫£i th√≠ch Ti·∫øng Anh (n·∫øu c√≥)
        giai_thich_en_arr = cau.get("giai_thich_en", [])
        if isinstance(giai_thich_en_arr, list) and len(giai_thich_en_arr) > 0:
            self.doc.add_paragraph("(translate_en)").italic = True
           
            for item in giai_thich_en_arr:
                # D√≤ng ti√™u ƒë·ªÅ EN
                p_title_en = self.doc.add_paragraph()
               
                prefix_run_en = p_title_en.add_run(f"+ ({item.get('ky_hieu', '')}.) ")
                prefix_run_en.bold = False
               
                # L·∫•y n·ªôi dung √Ω EN
                ky_hieu_curr = item.get('ky_hieu', '')
                noi_dung_y_en = ""
                for y in cau.get("cac_y", []):
                    if y.get('ky_hieu') == ky_hieu_curr:
                        noi_dung_y_en = y.get('noi_dung_en', y.get('noi_dung', ''))
                        break
               
                if noi_dung_y_en:
                    process_text_with_latex(noi_dung_y_en, p_title_en, bold=False)
                    p_title_en.add_run(". ")
               
                # K·∫øt lu·∫≠n EN (IN ƒê·∫¨M)
                ket_luan_en_run = p_title_en.add_run(item.get('ket_luan', ''))
                ket_luan_en_run.bold = True
               
                # Gi·∫£i th√≠ch chi ti·∫øt EN
                p_detail_en = self.doc.add_paragraph()
                process_text_with_latex(item.get('noi_dung', ''), p_detail_en, bold=False)  
    
    def render_question_tra_loi_ngan(self, cau: Dict):
        self.render_ma_dang_header(cau.get("ma_dang"))
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        process_text_with_latex(cau.get('noi_dung', ''), p)  
        
        # 2. C√¢u h·ªèi Ti·∫øng Anh
        if cau.get('noi_dung_en'):
            self.doc.add_paragraph("(translate_en)").italic = True
            p_en = self.doc.add_paragraph()
            process_text_with_latex(cau.get('noi_dung_en', ''), p_en)

        # 3. H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # 4. ƒê√°p √°n
        p_da = self.doc.add_paragraph()
        run_label = p_da.add_run("ƒê√°p √°n: ")
        run_label.bold = True
        
        raw_ans = str(cau.get('dap_an', '')).strip()
        if not (raw_ans.startswith("[[") and raw_ans.endswith("]]")):
            final_ans = f"[[{raw_ans}]]"
        else:
            final_ans = raw_ans
        process_text_with_latex(final_ans, p_da, bold=True)  
        
        # 5. L·ªùi gi·∫£i Header
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        self.doc.add_paragraph("####")
        
        # --- H√ÄM HELPER M·ªöI: CHU·∫®N H√ìA D√íNG TR·ªêNG ---
        def render_explanation_block(text_content, lang='vi'):
            if not text_content: return
            
            # 1. Chu·∫©n h√≥a xu·ªëng d√≤ng: Bi·∫øn \n\n, \n\s*\n th√†nh 1 \n duy nh·∫•t
            # X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát \\n tr∆∞·ªõc
            clean_text = text_content.replace('\\n', '\n')
            # Regex g·ªôp nhi·ªÅu d√≤ng tr·ªëng th√†nh 1
            clean_text = re.sub(r'\n\s*\n', '\n', clean_text)
            
            lines = clean_text.split('\n')
            
            for line in lines:
                text = line.strip()
                # B·ªè qua d√≤ng r·ªóng ho·∫∑c d√≤ng ch·ªâ c√≥ d·∫•u ####
                if not text or text == "####": continue
                
                is_bold = False
                # X·ª≠ l√Ω markdown bold th·ªß c√¥ng t·ª´ AI
                if text.startswith("**") and text.endswith("**"):
                    text = text[2:-2]
                    is_bold = True
                
                # Auto-detect d√≤ng k·∫øt lu·∫≠n ƒë·ªÉ in ƒë·∫≠m
                text_lower = text.lower()
                if lang == 'vi' and (text_lower.startswith("v·∫≠y") or text_lower.startswith("k·∫øt lu·∫≠n") or "(kl.)" in text_lower):
                    is_bold = True
                elif lang == 'en' and (text_lower.startswith("therefore") or text_lower.startswith("conclusion")):
                    is_bold = True
                
                text = text.replace('**', '') 
                p_gt = self.doc.add_paragraph()
                process_text_with_latex(text, p_gt, bold=is_bold)

        # 6. Render Gi·∫£i th√≠ch
        render_explanation_block(cau.get("giai_thich", ""), lang='vi')

        if cau.get("giai_thich_en"):
            self.doc.add_paragraph("(translate_en)").italic = True
            render_explanation_block(cau.get("giai_thich_en", ""), lang='en')  

    def render_question_tu_luan(self, cau: Dict):
        self.render_ma_dang_header(cau.get("ma_dang"))
        """Render c√¢u h·ªèi T·ª± lu·∫≠n (ƒê√£ fix l·ªói kho·∫£ng c√°ch d√≤ng)"""
        # 1. C√¢u h·ªèi Ti·∫øng Vi·ªát
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        process_text_with_latex(cau.get('noi_dung', ''), p)
        
        # 2. C√¢u h·ªèi Ti·∫øng Anh
        if cau.get('noi_dung_en'):
            self.doc.add_paragraph("(translate_en)").italic = True
            p_en = self.doc.add_paragraph()
            process_text_with_latex(cau.get('noi_dung_en', ''), p_en)
        
        # 3. H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
            
        # 4. Header L·ªùi gi·∫£i
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        # self.doc.add_paragraph("####")
        
        # --- H√ÄM HELPER M·ªöI: CHU·∫®N H√ìA D√íNG TR·ªêNG ---
        def render_essay_solution(text_content, lang='vi'):
            if not text_content: return
            
            # 1. Chu·∫©n h√≥a: G·ªôp d√≤ng tr·ªëng th·ª´a
            clean_text = text_content.replace('\\n', '\n')
            clean_text = re.sub(r'\n\s*\n', '\n', clean_text)
            
            lines = clean_text.split('\n')
            
            for line in lines:
                text = line.strip()
                # QUAN TR·ªåNG: K√≠ch ho·∫°t l·∫°i b·ªô l·ªçc d√≤ng tr·ªëng
                if not text or text == "####": continue
                
                # Logic in ƒë·∫≠m
                is_bold = False
                text_lower = text.lower()
                
                if (text.startswith("**") and text.endswith("**")):
                    text = text[2:-2]
                    is_bold = True
                elif lang == 'vi' and (text_lower.startswith("v·∫≠y") or "(kl.)" in text_lower):
                    is_bold = True
                elif lang == 'en' and text_lower.startswith("therefore"):
                    is_bold = True
                
                text = text.replace('**', '')
                p_gt = self.doc.add_paragraph()
                process_text_with_latex(text, p_gt, bold=is_bold)

        # 5. Render Gi·∫£i th√≠ch
        render_essay_solution(cau.get("giai_thich", ""), lang='vi')

        if cau.get("giai_thich_en"):
            self.doc.add_paragraph("(translate_en)").italic = True
            render_essay_solution(cau.get("giai_thich_en", ""), lang='en')   
    
    def render_all(self, data: Dict):
        """
        Main render function - C√≥ h·ªó tr·ª£ chia PH·∫¶N (PART) b√™n trong M·ª©c ƒë·ªô
        """
        self.render_title(data)
        
        # 1. Auto-group theo m·ª©c ƒë·ªô (Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu...)
        grouped = self.auto_group_questions(data)
        
        # 2. Detect lo·∫°i ƒë·ªÅ
        loai_de = data.get("loai_de", "")
        ma_bai = data.get("ma_bai", "")
        
        # 3. Render t·ª´ng nh√≥m M·ª®C ƒê·ªò
        # Th·ª© t·ª± ∆∞u ti√™n render
        order_muc_do = ["nhan_biet", "thong_hieu", "van_dung", "van_dung_cao"]
        
        for muc_do in order_muc_do:
            if muc_do not in grouped:
                continue
            
            # L·∫•y danh s√°ch c√¢u h·ªèi trong m·ª©c ƒë·ªô n√†y
            questions = grouped[muc_do]
            if not questions:
                continue
            section_title = self.get_section_title(muc_do)
            self.doc.add_heading(section_title, level=2)
            current_phan = None

            for cau in questions:
                # L·∫•y t√™n ph·∫ßn c·ªßa c√¢u hi·ªán t·∫°i
                raw_phan = cau.get("phan", [])
                
                # X·ª≠ l√Ω: N·∫øu l√† List th√¨ n·ªëi l·∫°i th√†nh chu·ªói ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp
                if isinstance(raw_phan, list):
                    # V√≠ d·ª•: "B√†i 1 - Ph·∫ßn 2 - D·∫°ng b√†i..."
                    phan_cua_cau = " - ".join([str(x) for x in raw_phan if x])
                else:
                    # Fallback n·∫øu AI l·ª° tr·∫£ v·ªÅ string c≈©
                    phan_cua_cau = str(raw_phan).strip()
                
                # N·∫øu c√¢u n√†y thu·ªôc m·ªôt ph·∫ßn m·ªõi -> In Header Ph·∫ßn
                if phan_cua_cau and phan_cua_cau != current_phan:
                    # In ra header c·∫•p 3 (VD: Ph·∫ßn 1: ƒê·ªôi ng≈©...)
                    # D√πng m√†u ho·∫∑c in ƒë·∫≠m ƒë·ªÉ ph√¢n bi·ªát
                    p_phan = self.doc.add_heading(phan_cua_cau.upper(), level=3)
                    p_phan.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    current_phan = phan_cua_cau
                
                # Render n·ªôi dung c√¢u h·ªèi nh∆∞ b√¨nh th∆∞·ªùng
                if loai_de == "dung_sai":
                    self.render_question_dung_sai(cau)
                elif loai_de == "tra_loi_ngan":
                    self.render_question_tra_loi_ngan(cau)
                elif loai_de == "tu_luan":  # [TH√äM M·ªöI]
                    self.render_question_tu_luan(cau)
                else:
                    self.render_question_trac_nghiem(cau)

def clean_json_response(text):
    """L√†m s·∫°ch chu·ªói tr·∫£ v·ªÅ t·ª´ AI, lo·∫°i b·ªè markdown v√† k√Ω t·ª± th·ª´a"""
    try:
        # Lo·∫°i b·ªè c√°c tag ```json ho·∫∑c ``` n·∫øu c√≥
        clean_text = re.sub(r'```json|```', '', text).strip()
        return clean_text
    except Exception:
        return text
 
import re

def roman_to_int(s):
    """Chuy·ªÉn s·ªë La M√£ sang s·ªë nguy√™n (H·ªó tr·ª£ I..XX)"""
    s = s.upper().strip().replace('.', '').replace(':', '').replace(')', '')
    romans = {'I': 1, 'V': 5, 'X': 10}
    
    # Map nhanh c√°c s·ªë nh·ªè hay g·∫∑p ƒë·ªÉ t·ªëc ƒë·ªô cao nh·∫•t
    fast_map = {
        'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,
        'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10,
        'XI': 11, 'XII': 12
    }
    if s in fast_map: return fast_map[s]
    return None

def renumber_ma_dang_global(all_questions, reference_ma_bai):
    """
    [SPECIALIZED FUNCTION FOR DUNG_SAI ONLY]
    Logic: 
    1. B·ªè qua ID M·ª•c/Ph·∫ßn.
    2. Ch·ªâ ƒë·∫øm ID D·∫°ng tƒÉng d·∫ßn (Global Counter).
    3. C·∫•u tr√∫c output: [MA_BAI]_[ID_D·∫†NG] (V√≠ d·ª•: SN_HOA_10_1_1_1, SN_HOA_10_1_1_2...)
    """
    print(f"üîß [DungSai Only] Chu·∫©n h√≥a M√£ D·∫°ng (No-Section) cho: {reference_ma_bai}")
    
    # B·ªô nh·ªõ map t√™n d·∫°ng -> ID (D√πng chung cho c·∫£ b√†i)
    type_memory = {} 
    
    # B·ªô ƒë·∫øm ID d·∫°ng to√†n c·ª•c (b·∫Øt ƒë·∫ßu t·ª´ 0)
    global_dang_counter = 0
    
    final_questions = []
    
    # Bi·∫øn fallback ph√≤ng khi AI tr·∫£ thi·∫øu m·∫£ng phan
    last_known_phan = [reference_ma_bai, "M·ª•c 1", "D·∫°ng t·ªïng qu√°t"]

    for index, q in enumerate(all_questions):
        # 1. C·∫≠p nh·∫≠t STT chu·∫©n (cho ch·∫Øc ch·∫Øn)
        q['stt'] = index + 1
        
        # 2. L·∫•y d·ªØ li·ªáu ph√¢n c·∫•p
        raw_phan = q.get("phan", [])
        if not isinstance(raw_phan, list) or len(raw_phan) < 3:
            raw_phan = list(last_known_phan)
        else:
            last_known_phan = raw_phan

        # T√°ch c√°c th√†nh ph·∫ßn (Ch·ªâ d√πng ƒë·ªÉ hi·ªÉn th·ªã ho·∫∑c map key)
        ten_bai = str(raw_phan[0]).strip()
        ten_muc = str(raw_phan[1]).strip()
        ten_dang = str(raw_phan[2]).strip() # Key quan tr·ªçng nh·∫•t
        
        # 3. THU·∫¨T TO√ÅN G√ÅN ID (GLOBAL - NO SECTION)
        # Ch·ªâ quan t√¢m t√™n d·∫°ng. N·∫øu t√™n d·∫°ng tr√πng -> ID c≈©. N·∫øu m·ªõi -> ID m·ªõi.
        if ten_dang in type_memory:
            current_dang_id = type_memory[ten_dang]
        else:
            global_dang_counter += 1
            current_dang_id = global_dang_counter
            type_memory[ten_dang] = current_dang_id

        # 4. T·∫°o chu·ªói ma_dang chu·∫©n: MA_BAI + "_" + ID_DANG
        final_ma_dang = f"{reference_ma_bai}_{current_dang_id}"
        
        q['ma_dang'] = final_ma_dang
        # C·∫≠p nh·∫≠t l·∫°i phan ƒë·ªÉ ƒë·∫£m b·∫£o th·ªëng nh·∫•t
        q['phan'] = [ten_bai, ten_muc, ten_dang] 
        
        final_questions.append(q)

    print(f"   ‚úÖ [DungSai] ƒê√£ map {global_dang_counter} d·∫°ng b√†i duy nh·∫•t.")
    return final_questions

def process_dung_sai_smart_batch(file_path, base_prompt, file_name, project_id, creds, model_name, batch_name):
    """
    Quy tr√¨nh x·ª≠ l√Ω ƒê√öNG/SAI (Fixed Logic): 
    - Batch 1 (1-20): 100% TH√îNG HI·ªÇU.
    - Batch 2 (21-40): 10 V·∫¨N D·ª§NG + 10 V·∫¨N D·ª§NG CAO.
    - Clean tr∆∞·ªùng 'phan' ƒë·ªÉ kh√¥ng b·ªã d√≠nh t·ª´ kh√≥a m·ª©c ƒë·ªô.
    """
    from modules.common.callAPI import VertexClient
    client = VertexClient(project_id, creds, model_name)
    
    # --- C·∫§U H√åNH BATCH (TU√ÇN TH·ª¶ 20 TH√îNG HI·ªÇU) ---
    batches = [
        {
            "range": "1-20", 
            # Instruction g·ª≠i cho AI: √âp sinh Th√¥ng hi·ªÉu
            "level_desc": "Y√äU C·∫¶U: Sinh 20 c√¢u TH√îNG HI·ªÇU (Gi·∫£i th√≠ch, so s√°nh, ph√¢n bi·ªát b·∫£n ch·∫•t). KH√îNG sinh c√¢u Nh·∫≠n bi·∫øt (ƒë·ªãnh nghƒ©a ƒë∆°n gi·∫£n).", 
            "mode": "thong_hieu" 
        },
        {
            "range": "21-40", 
            # Instruction g·ª≠i cho AI: √âp sinh V·∫≠n d·ª•ng & V·∫≠n d·ª•ng cao
            "level_desc": "Y√äU C·∫¶U: 10 c√¢u V·∫¨N D·ª§NG (T√≠nh to√°n, √°p d·ª•ng c√¥ng th·ª©c) v√† 10 c√¢u V·∫¨N D·ª§NG CAO (Suy lu·∫≠n, t·ªïng h·ª£p, b√†i to√°n ng∆∞·ª£c).", 
            "mode": "van_dung" # Mode t·∫°m, s·∫Ω override chi ti·∫øt b√™n d∆∞·ªõi
        }
    ]

    all_raw_questions = []
    reference_ma_bai = "SN_UNK" 
    
    print(f"\nüöÄ [DungSai] Ch·∫°y ch·∫ø ƒë·ªô Smart Batch (20 Th√¥ng hi·ªÉu - 10 V·∫≠n d·ª•ng - 10 VDC) cho: {batch_name}")

    for idx, batch in enumerate(batches):
        print(f"   ‚ñ∫ Batch {idx+1}: C√¢u {batch['range']}...")
        
        batch_instruction = f"""
{base_prompt}
--------------------------------------------------------------------------------
‚ö†Ô∏è L·ªÜNH TH·ª∞C THI BATCH {idx+1}/2:
1. PH·∫†M VI STT: {batch['range']}.
2. Y√äU C·∫¶U M·ª®C ƒê·ªò: {batch['level_desc']}
3. QUY ƒê·ªäNH NGHI√äM NG·∫∂T: 
   - Tr∆∞·ªùng "phan" CH·ªà ƒê∆Ø·ª¢C CH·ª®A: ["T√™n B√†i", "T√™n M·ª•c", "T√™n D·∫°ng"]. 
   - C·∫§M ƒë∆∞a t·ª´ kh√≥a "Th√¥ng hi·ªÉu", "V·∫≠n d·ª•ng" v√†o tr∆∞·ªùng "phan".
   - Tr√≠ch xu·∫•t M√£ B√†i (ma_bai) chu·∫©n SN_[M√îN]...
--------------------------------------------------------------------------------
"""
        try:
            raw_text = client.send_data_to_AI(batch_instruction, file_path, response_schema=schema_dung_sai, max_output_tokens=65534)
            if not raw_text: continue

            data = json.loads(clean_json_response(raw_text))
            batch_questions = data.get("cau_hoi", [])
            
            # --- CODE FIX: CLEAN 'PHAN' & FORCE 'MUC_DO' ---
            keywords_to_remove = ["nh·∫≠n bi·∫øt", "th√¥ng hi·ªÉu", "v·∫≠n d·ª•ng", "m·ª©c ƒë·ªô", "level", "nhan_biet", "thong_hieu", "van_dung"]
            
            for q in batch_questions:
                # 1. Clean tr∆∞·ªùng 'phan' (X√≥a c√°c t·ª´ kh√≥a m·ª©c ƒë·ªô n·∫øu AI l·ª° ƒëi·ªÅn v√†o)
                raw_phan = q.get("phan", [])
                if isinstance(raw_phan, list):
                    clean_phan = []
                    for p_item in raw_phan:
                        p_str = str(p_item)
                        # N·∫øu d√≤ng n√†y ch·ª©a t·ª´ kh√≥a c·∫•m -> Kh√¥ng add v√†o, ho·∫∑c clean nh·∫π
                        # ·ªû ƒë√¢y ta ch·ªçn gi·∫£i ph√°p: N·∫øu ch·ª©a t·ª´ kh√≥a m·ª©c ƒë·ªô -> B·ªè qua ph·∫ßn t·ª≠ ƒë√≥ lu√¥n
                        if not any(kw in p_str.lower() for kw in keywords_to_remove):
                             clean_phan.append(p_str)
                    
                    # N·∫øu clean xong b·ªã r·ªóng ho·∫∑c m·∫•t d·∫°ng -> Fallback nh·∫π
                    if len(clean_phan) < 3:
                        # Gi·ªØ nguy√™n b·∫£n g·ªëc n·∫øu clean l√†m h·ªèng c·∫•u tr√∫c (ch·∫•p nh·∫≠n x·∫•u c√≤n h∆°n l·ªói code)
                        pass 
                    else:
                        q['phan'] = clean_phan
                
                # 2. Force M·ª©c ƒë·ªô (Ghi ƒë√® c·ª©ng theo logic STT c·ªßa b·∫°n)
                stt = q.get("stt", 0)
                
                # Logic: 20 Th√¥ng hi·ªÉu -> 10 V·∫≠n d·ª•ng -> 10 VDC
                if 1 <= stt <= 20:
                    q['muc_do'] = "thong_hieu"
                elif 21 <= stt <= 30:
                    q['muc_do'] = "van_dung"
                elif 31 <= stt <= 40:
                    q['muc_do'] = "van_dung_cao"
                # (C√°c c√¢u ngo√†i range n√†y s·∫Ω gi·ªØ nguy√™n gi√° tr·ªã AI tr·∫£ v·ªÅ)

            if idx == 0:
                raw_ma = data.get("ma_bai", "")
                if raw_ma and raw_ma.startswith("SN_") and raw_ma.count("_") >= 3:
                    reference_ma_bai = raw_ma
                else:
                    if reference_ma_bai == "SN_UNK": reference_ma_bai = f"SN_UNK_{batch_name}"

            all_raw_questions.extend(batch_questions)
            print(f"      ‚úÖ Batch {idx+1} OK: +{len(batch_questions)} c√¢u.")
            
        except Exception as e:
            print(f"      ‚ùå L·ªói Batch {idx+1}: {e}")

    if not all_raw_questions: return None

    # G·ªçi Renumber (Logic b·ªè M·ª•c, ch·ªâ gi·ªØ ID d·∫°ng tƒÉng d·∫ßn)
    final_questions = renumber_ma_dang_global(all_raw_questions, reference_ma_bai)
    
    return {
        "loai_de": "dung_sai",
        "tong_so_cau": len(final_questions),
        "ma_bai": reference_ma_bai,
        "cau_hoi": final_questions
    }

# ==============================================================================
# MAIN ENTRY POINT
# ==============================================================================

def response2docx_flexible(file_path, prompt, file_name, project_id, creds, model_name, question_type="trac_nghiem_4_dap_an", batch_name=None):
    if not batch_name:
        batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
        
    try:
        final_json_data = None

        # 1. LOGIC RI√äNG CHO ƒê√öNG/SAI (C√≥ can thi·ªáp code renumber)
        if question_type == "dung_sai":
            final_json_data = process_dung_sai_smart_batch(
                file_path, prompt, file_name, project_id, creds, model_name, batch_name
            )

        # 2. LOGIC CHO C√ÅC D·∫†NG KH√ÅC (Tuy·ªát ƒë·ªëi tin t∆∞·ªüng Prompt AI, kh√¥ng renumber)
        else:
            from modules.common.callAPI import VertexClient
            client = VertexClient(project_id, creds, model_name)
            target_schema = get_schema_by_type(question_type)
            final_prompt = PromptBuilder.wrap_user_prompt(prompt)
            
            print(f"üì§ [{question_type}] ƒêang g·ª≠i request (1-shot)...")
            ai_response_text = client.send_data_to_AI(
                final_prompt, file_path, response_schema=target_schema, max_output_tokens=65534
            )
            
            if ai_response_text:
                final_json_data = json.loads(clean_json_response(ai_response_text))
            
            # KH√îNG G·ªåI renumber_ma_dang_global ·ªü ƒë√¢y.
            # D·ªØ li·ªáu AI tr·∫£ v·ªÅ sao th√¨ d√πng v·∫≠y.

        # --- PH·∫¶N CHUNG: L∆ØU FILE ---
        if not final_json_data: 
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu.")
            return None
        
        print(f"üíæ [{batch_name}] L∆∞u JSON...")
        save_json_securely(final_json_data, batch_name, file_name)
        
        print(f"üìù [{batch_name}] Render DOCX...")
        doc = Document()
        renderer = DynamicDocxRenderer(doc)
        renderer.render_all(final_json_data)
        
        output_path = save_document_securely(doc, batch_name, file_name)
        if output_path: print(f"‚úÖ HO√ÄN TH√ÄNH: {output_path}")
        return output_path

    except Exception as e:
        print(f"‚ùå L·ªói h·ªá th·ªëng: {e}")
        traceback.print_exc()
        return None

# def response2docx_flexible(
#     file_path: str,
#     prompt: str,
#     file_name: str,
#     project_id: str,
#     creds: str,
#     model_name: str,
#     question_type: str = "trac_nghiem_4_dap_an",
#     batch_name: str = None
# ):
#     try:
#         from modules.common.callAPI import VertexClient
#         client = VertexClient(project_id, creds, model_name)
#         if not batch_name:
#             batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
            
#         target_schema = get_schema_by_type(question_type)
#         final_prompt = PromptBuilder.wrap_user_prompt(prompt)
        
#         print(f"üì§ ƒêang g·ª≠i request (Schema: {question_type})...")
#         ai_response_text = client.send_data_to_AI(
#             final_prompt, 
#             file_path, 
#             response_schema=target_schema,
#             max_output_tokens=65534
#         )
        
#         if not ai_response_text:
#             print("‚ùå AI kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu.")
#             return None

#         print("üîÑ ƒêang parse JSON...")
#         try:
#             data = json.loads(ai_response_text)
#         except json.JSONDecodeError as e:
#             print(f"‚ùå L·ªói JSON b·∫•t ng·ªù: {e}")
#             if "```json" in ai_response_text:
#                 clean_text = ai_response_text.split("```json")[1].split("```")[0]
#                 data = json.loads(clean_text)
#             else:
#                 return None

#         print(f"‚úÖ Parse th√†nh c√¥ng: {data.get('tong_so_cau', 0)} c√¢u h·ªèi")
        
#         # --- [M·ªöI] L∆ØU FILE JSON ---
#         print("üíæ ƒêang l∆∞u file JSON...")
#         save_json_securely(data, batch_name, file_name)
#         # ---------------------------

#         print("üìù ƒêang t·∫°o DOCX...")
#         doc = Document()
#         renderer = DynamicDocxRenderer(doc)
        
#         try:
#             renderer.render_all(data)
#         except Exception as render_err:
#              print(f"‚ùå L·ªói Render: {render_err}")
#              traceback.print_exc()

#         print("üíæ ƒêang l∆∞u file DOCX...")
#         output_path = save_document_securely(doc, batch_name, file_name)
#         return output_path

#     except Exception as e:
#         print(f"‚ùå L·ªói h·ªá th·ªëng: {e}")
#         traceback.print_exc()
#         return None

#     except Exception as e_main:
#         print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG TRONG TO√ÄN B·ªò H√ÄM: {e_main}")
#         traceback.print_exc()
#         try:
#             doc = Document()
#             doc.add_heading('L·ªñI H·ªÜ TH·ªêNG', level=1).alignment = WD_ALIGN_PARAGRAPH.CENTER
#             doc.add_paragraph(f'L·ªói nghi√™m tr·ªçng: {e_main}')
#             doc.add_paragraph('H·ªá th·ªëng kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu.')
            
#             if not batch_name:
#                 batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
#             fallback_path = os.path.join(ensure_output_folder_for_batch(batch_name), f"{file_name}_loi_he_thong.docx")
            
#             doc.save(fallback_path)
#             return fallback_path
#         except Exception as e_final:
#             return None

def response2docx_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫Øc nghi·ªám 4 ƒë√°p √°n (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="trac_nghiem_4_dap_an",
        batch_name=batch_name
    )

def response2docx_dung_sai_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho ƒë√∫ng/sai (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="dung_sai",
        batch_name=batch_name
    )
    
def response2docx_tra_loi_ngan_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫£ l·ªùi ng·∫Øn (legacy compatibility)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="tra_loi_ngan",
        batch_name=batch_name
    )

def response2docx_tu_luan_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho t·ª± lu·∫≠n h·ªçc li·ªáu"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="tu_luan", # Key n√†y s·∫Ω k√≠ch ho·∫°t logic trong PromptBuilder v√† Renderer
        batch_name=batch_name
    )