import json
import os
import sys
import threading
import time
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
from typing import Dict, List, Optional, Any
import zipfile
import subprocess
import re
from tempfile import NamedTemporaryFile
from docx.oxml import parse_xml
import traceback

_FILE_LOCK = threading.RLock()
_OUTPUT_DIR_LOCK = threading.RLock()

def get_app_path():
    """L·∫•y ƒë∆∞·ªùng d·∫´n ch·ª©a file .exe ho·∫∑c script"""
    if getattr(sys, 'frozen', False):
        return os.path.dirname(sys.executable)
    return os.path.dirname(os.path.abspath(__file__))
def find_pandoc_executable():
    """
    T√¨m pandoc.exe theo th·ª© t·ª± ∆∞u ti√™n:
    1. Th∆∞ m·ª•c 'pandoc' c·∫°nh tool (cho b·∫£n build)
    2. PATH h·ªá th·ªëng (cho m√¥i tr∆∞·ªùng dev)
    """
    app_path = get_app_path()
    
    # 1. T√¨m trong th∆∞ m·ª•c c·ª•c b·ªô 'pandoc' (∆∞u ti√™n cao nh·∫•t)
    local_pandoc = os.path.join(app_path, 'pandoc', 'pandoc.exe')
    if os.path.isfile(local_pandoc):
        # print(f"‚úÖ S·ª≠ d·ª•ng Pandoc c·ª•c b·ªô: {local_pandoc}")
        return local_pandoc
    
    # 2. Fallback: T√¨m trong PATH h·ªá th·ªëng (cho dev)
    import shutil
    system_pandoc = shutil.which('pandoc')
    if system_pandoc:
        # print(f"‚ö†Ô∏è S·ª≠ d·ª•ng Pandoc h·ªá th·ªëng: {system_pandoc}")
        return system_pandoc
    
    # 3. Kh√¥ng t√¨m th·∫•y
    print("‚ùå KH√îNG T√åM TH·∫§Y PANDOC!")
    return None

def latex_to_omml_via_pandoc(latex_math_dollar):
    """Chuy·ªÉn ƒë·ªïi LaTeX sang OMML qua Pandoc"""
    pandoc_exe = find_pandoc_executable()
    
    if not pandoc_exe:
        print("‚ùå Pandoc kh√¥ng kh·∫£ d·ª•ng, b·ªè qua equation")
        return None
    
    try:
        # Chu·∫©n h√≥a input (lo·∫°i b·ªè k√Ω t·ª± l·∫°)
        latex_clean = latex_math_dollar.strip()
        
        # T·∫°o file t·∫°m v·ªõi encoding UTF-8 BOM ƒë·ªÉ tr√°nh l·ªói
        with NamedTemporaryFile(mode='w', suffix=".docx", delete=False, encoding='utf-8') as temp_docx:
            temp_path = temp_docx.name
        
        # Ch·∫°y Pandoc v·ªõi error handling t·ªët h∆°n
        result = subprocess.run(
            [pandoc_exe, '--from=latex', '--to=docx', '-o', temp_path],
            input=latex_clean,
            text=True,
            encoding='utf-8',
            capture_output=True,
            timeout=10,  # Timeout 10s ƒë·ªÉ tr√°nh treo
            creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
        )
 
        if result.returncode != 0:
            error_msg = result.stderr.strip() if result.stderr else "Unknown error"
            print(f"‚ö†Ô∏è Pandoc error (code {result.returncode}): {error_msg}")
            
            # Ki·ªÉm tra l·ªói ph·ªï bi·∫øn
            if "not found" in error_msg.lower() or "cannot find" in error_msg.lower():
                print("   ‚Üí Thi·∫øu DLL dependencies. Ki·ªÉm tra l·∫°i folder pandoc/")
            elif "syntax" in error_msg.lower():
                print(f"   ‚Üí LaTeX syntax error: {latex_clean[:50]}...")
            
            return None
        
        # Ki·ªÉm tra file output c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(temp_path) or os.path.getsize(temp_path) == 0:
            print(f"‚ö†Ô∏è Pandoc kh√¥ng t·∫°o file output h·ª£p l·ªá")
            return None
           
        # ƒê·ªçc XML t·ª´ DOCX
        with zipfile.ZipFile(temp_path, 'r') as z:
            xml_content = z.read('word/document.xml').decode('utf-8')
        
        # D·ªçn d·∫πp file t·∫°m
        try:
            os.remove(temp_path)
        except:
            pass
       
        # T√¨m equation XML
        match = re.search(r'(<m:oMath[^>]*>.*?</m:oMath>)', xml_content, re.DOTALL)
        
        if not match:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y equation trong output: {latex_clean[:30]}...")
            return None
            
        return match.group(1)
   
    except subprocess.TimeoutExpired:
        print(f"‚ö†Ô∏è Pandoc timeout (>10s)")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói latex_to_omml: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None



def process_text_with_latex(text, paragraph, bold=False):
    """
    X·ª≠ l√Ω text c√≥ c√¥ng th·ª©c LaTeX
    VERSION ·ªîN ƒê·ªäNH - Copy t·ª´ test_res.py (KH√îNG c√≥ repair_broken_latex)
    """
    if not text:
        return
    
    # L√†m s·∫°ch HTML tags
    text = text.replace("<br>", "\n").replace("<br/>", "\n") \
               .replace("<Br>", "\n").replace("<Br/>", "\n")
    text = re.sub(r'</?(div|p|u|span|font|i|b)\b[^>]*>', '', text)
    text = text.replace("&nbsp;", "").replace("&lt;", "").replace("&gt;", "")
    
    # T√°ch text v√† LaTeX
    pattern = r'(\$[^$]+\$|\\\[.*?\\\])'
    parts = re.split(pattern, text)
    
    for part in parts:
        if not part:
            continue
        
        # Ph·∫ßn LaTeX
        if part.startswith('$') or part.startswith('\\['):
            try:
                latex_expr = clean_latex_math(part)
                insert_equation_into_paragraph(latex_expr, paragraph)
            except Exception as e:
                # Fallback: th√™m text thu·∫ßn
                run = paragraph.add_run(part)
                if bold:
                    run.bold = True
        # Ph·∫ßn text th∆∞·ªùng
        else:
            cleaned_part = re.sub(r'^\s*/', '', part)
            run = paragraph.add_run(cleaned_part)
            if bold:
                run.bold = True


def insert_equation_into_paragraph(latex_math_dollar, paragraph):
    """Ch√®n c√¥ng th·ª©c to√°n h·ªçc v√†o paragraph"""
    omml_str = latex_to_omml_via_pandoc(latex_math_dollar)
    
    if not omml_str:
        # Fallback: Th√™m text thu·∫ßn n·∫øu kh√¥ng convert ƒë∆∞·ª£c
        paragraph.add_run(f" [{latex_math_dollar}] ")
        return
    
    # Th√™m namespace n·∫øu thi·∫øu
    if 'xmlns:m=' not in omml_str:
        omml_str = re.sub(
            r'<m:oMath',
            r'<m:oMath xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"',
            omml_str,
            count=1
        )
    
    try:
        omml_element = parse_xml(omml_str)
        run = paragraph.add_run()
        run._r.append(omml_element)
    except Exception as e:
        print(f"L·ªói ch√®n equation: {e}")
        paragraph.add_run(f" [{latex_math_dollar}] ")


def clean_latex_math(latex_raw):
    latex_raw = re.sub(r'\\/', '', latex_raw)
    latex_raw = re.sub(r'\\operatorname\s*{\s*([^}]*)\s*}',
                       lambda m: m.group(1).replace(' ', ''), latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*{(\d+)}\s*\\of\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'\\root\s*(\d+)\s*\\sqrt\s*{([^}]*)}', r'\\sqrt[\1]{\2}', latex_raw)
    latex_raw = re.sub(r'([a-zA-Z])\s*\\frac\s*{([^}]+)}\s*{([^}]+)}',
                       r'\1^{\\frac{\2}{\3}}', latex_raw)
    latex_raw = re.sub(r'\\sp\s*{([^}]*)}', r'^{\1}', latex_raw)
    latex_raw = re.sub(r'{\\bf\s*([^}]*)}', r'\1', latex_raw)
    latex_raw = re.sub(r'\\\s*log', r'\\log', latex_raw)
    latex_raw = re.sub(r'\\bigskip', '', latex_raw)
    latex_raw = re.sub(r'\\nonumber', '', latex_raw)
    latex_raw = latex_raw.replace(r'\?', '?')
    latex_raw = re.sub(r'\\cdot\s*(?=\w)', r'\\cdot ', latex_raw)
    latex_raw = latex_raw.replace(r'\dotstan', r'\cdot \tan')
    latex_raw = re.sub(r'(?<!\\)(\bln\b|\blog\b|\bsin\b|\bcos\b|\btan\b|\blog_{?\d*}?)',
                       r'\\\1', latex_raw)
    latex_raw = re.sub(r'(\\Leftrightarrow|\\Rightarrow|\\rightarrow)(?=\w)', r'\1 ', latex_raw)
    latex_raw = latex_raw.replace(r'\\n', r'\n')
    
    latex_raw = latex_raw.strip()
    # ‚úÖ KH√ÅC BI·ªÜT: Version c≈© KH√îNG replace \n v√† \r
    # latex_raw = latex_raw.replace('\n', ' ').replace('\r', '')  # ‚Üê X√ìA D√íNG N√ÄY
    
    if not (latex_raw.startswith('$') and latex_raw.endswith('$')):
        latex_raw = f"${latex_raw}$"
    
    return latex_raw

def ensure_output_folder_for_batch(batch_name):
    """T·∫°o folder ri√™ng cho batch"""
    base_path = get_app_path()
    output_base = os.path.join(base_path, "output")
    batch_folder = os.path.join(output_base, batch_name)
    
    with _OUTPUT_DIR_LOCK:
        os.makedirs(output_base, exist_ok=True)
        os.makedirs(batch_folder, exist_ok=True)
    
    return batch_folder

def save_document_securely(doc, batch_name, file_name):
    """L∆∞u file DOCX v·ªõi thread-safety"""
    batch_folder = ensure_output_folder_for_batch(batch_name)
    if not batch_folder:
        return None

    output_path = os.path.join(batch_folder, f"{file_name}.docx")
    
    with _FILE_LOCK:
        max_retries = 3
        for retry_count in range(max_retries):
            try:
                doc.save(output_path)
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    print(f"‚úÖ ƒê√£ l∆∞u file: {output_path} ({file_size} bytes)")
                    return output_path
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói l∆∞u file l·∫ßn {retry_count + 1}: {e}")
                if retry_count < max_retries - 1:
                    time.sleep(1)
        
        print(f"‚ùå Kh√¥ng th·ªÉ l∆∞u file sau {max_retries} l·∫ßn th·ª≠")
        return None
def repair_json_with_ai(broken_json_str: str, client) -> str:
    """
    G·ª≠i JSON l·ªói cho AI s·ª≠a (ƒê√É C·∫¢I TI·∫æN)
    Thay v√¨ y√™u c·∫ßu AI tr·∫£ v·ªÅ to√†n b·ªô JSON, ta s·∫Ω c·ªë g·∫Øng t√¨m ph·∫ßn h·ª£p l·ªá
    ho·∫∑c y√™u c·∫ßu AI s·ª≠a ph·∫ßn b·ªã l·ªói c·ª• th·ªÉ.
    """
    print("‚ö†Ô∏è JSON l·ªói. ƒêang c·ªë g·∫Øng s·ª≠a...")
    
    # --- C·∫£i ti·∫øn 1: C·ªë g·∫Øng "x√©n" JSON h·ª£p l·ªá ---
    # ƒê√¥i khi AI tr·∫£ v·ªÅ JSON b·ªã th·ª´a vƒÉn b·∫£n ph√≠a sau
    repaired_by_cutting = extract_valid_json(broken_json_str)
    if repaired_by_cutting:
        print("‚úÖ JSON ƒë√£ ƒë∆∞·ª£c s·ª≠a b·∫±ng c√°ch x√©n ph·∫ßn h·ª£p l·ªá.")
        return repaired_by_cutting

    # --- C·∫£i ti·∫øn 2: G·ª≠i y√™u c·∫ßu s·ª≠a l·ªói c·ª• th·ªÉ h∆°n cho AI ---
    # Thay v√¨ g·ª≠i nguy√™n ƒëo·∫°n l·ªói, m√¥ t·∫£ r√µ h∆°n l·ªói g√¨
    error_description = "ƒêo·∫°n JSON sau b·ªã l·ªói c√∫ ph√°p ho·∫∑c b·ªã c·∫Øt x√©n."
    error_description += " C√≥ th·ªÉ thi·∫øu d·∫•u ph·∫©y, ngo·∫∑c ƒë√≥ng/m·ªü kh√¥ng kh·ªõp, ho·∫∑c b·ªã ng·∫Øt gi·ªØa ch·ª´ng."
    error_description += " Vui l√≤ng s·ª≠a l·ªói c√∫ ph√°p, GI·ªÆ NGUY√äN TO√ÄN B·ªò N·ªòI DUNG TI·∫æNG VI·ªÜT V√Ä C√îNG TH·ª®C LATEX,"
    error_description += " v√† TR·∫¢ V·ªÄ CH·ªà C√ì JSON ƒê√É S·ª¨A (kh√¥ng th√™m l·ªùi d·∫´n, kh√¥ng th√™m markdown)."

    prompt_fix = f"""
{error_description}

JSON l·ªói:
{broken_json_str}

JSON ƒë√£ s·ª≠a (ch·ªâ JSON, kh√¥ng th√™m g√¨ kh√°c):
"""
    try:
        repaired_text = client.send_data_to_check(prompt_fix)
        # Sau khi AI tr·∫£ v·ªÅ, th·ª≠ x√©n l·∫°i l·∫ßn n·ªØa n·∫øu c·∫ßn
        final_repaired = extract_valid_json(repaired_text)
        if final_repaired:
            print("‚úÖ JSON ƒë√£ ƒë∆∞·ª£c s·ª≠a b·ªüi AI v√† x√°c nh·∫≠n h·ª£p l·ªá.")
            return final_repaired
        else:
            print("‚ùå AI tr·∫£ v·ªÅ vƒÉn b·∫£n nh∆∞ng v·∫´n kh√¥ng ph·∫£i JSON h·ª£p l·ªá.")
            return repaired_text # Tr·∫£ v·ªÅ nguy√™n vƒÉn ƒë·ªÉ th·ª≠ parse sau
    except Exception as e:
        print(f"‚ùå G·∫∑p l·ªói khi y√™u c·∫ßu AI s·ª≠a JSON: {e}")
        return broken_json_str
    
def extract_valid_json(text: str) -> str:
    """
    C·ªë g·∫Øng tr√≠ch xu·∫•t ph·∫ßn JSON h·ª£p l·ªá t·ª´ m·ªôt chu·ªói c√≥ th·ªÉ c√≥ vƒÉn b·∫£n th·ª´a.
    H·ªó tr·ª£ c·∫£ JSON l·ªìng nhau ph·ª©c t·∫°p.
    """
    text = text.strip()
    
    # 1. T√¨m t·∫•t c·∫£ c√°c c·∫∑p ngo·∫∑c nh·ªçn {} ho·∫∑c ngo·∫∑c vu√¥ng []
    stack = []
    start = -1
    max_depth = 0
    max_start = -1
    max_end = -1

    for i, char in enumerate(text):
        if char == '{':
            if not stack:
                start = i
            stack.append(char)
        elif char == '[':
            if not stack:
                start = i
            stack.append(char)
        elif char == '}' and stack and stack[-1] == '{':
            stack.pop()
            if not stack and (i - start) > (max_end - max_start):
                max_start = start
                max_end = i
        elif char == ']' and stack and stack[-1] == '[':
            stack.pop()
            if not stack and (i - start) > (max_end - max_start):
                max_start = start
                max_end = i

    if max_start != -1 and max_end != -1:
        potential_json = text[max_start : max_end + 1]
        # 2. Th·ª≠ parse ph·∫ßn JSON n√†y
        try:
            # D√πng strict=False ƒë·ªÉ th∆∞ gi√£n m·ªôt ch√∫t v·ªõi k√Ω t·ª± ƒë·∫∑c bi·ªát
            json.loads(potential_json, strict=False)
            print(f"üîç ƒê√£ t√¨m th·∫•y JSON h·ª£p l·ªá trong vƒÉn b·∫£n.")
            return potential_json
        except (json.JSONDecodeError, TypeError):
            pass # Kh√¥ng parse ƒë∆∞·ª£c, th·ª≠ ph∆∞∆°ng ph√°p kh√°c

    # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c JSON ho√†n ch·ªânh, th·ª≠ ph∆∞∆°ng ph√°p c≈©
    # "SƒÉn" JSON b·∫±ng c√°ch t√¨m { ƒë·∫ßu v√† } cu·ªëi
    start_brace = text.find('{')
    end_brace = text.rfind('}')
    if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
        potential_json_old_way = text[start_brace : end_brace + 1]
        try:
            json.loads(potential_json_old_way, strict=False)
            print(f"üîç ƒê√£ t√¨m th·∫•y JSON h·ª£p l·ªá theo c√°ch c≈©.")
            return potential_json_old_way
        except (json.JSONDecodeError, TypeError):
            pass

    # N·∫øu t·∫•t c·∫£ ƒë·ªÅu kh√¥ng th√†nh c√¥ng
    return ""
def sanitize_latex_json(text: str) -> str:
    VALID_ESCAPES = {
        '\\\\', '\\"', '\\/', '\\b', '\\f', '\\n', '\\r', '\\t'
    }
    
    def is_already_escaped(s: str, pos: int) -> bool:
        """Ki·ªÉm tra backslash t·∫°i v·ªã tr√≠ pos ƒë√£ ƒë∆∞·ª£c escape ch∆∞a"""
        count = 0
        i = pos - 1
        while i >= 0 and s[i] == '\\':
            count += 1
            i -= 1
        return count % 2 == 1
    
    def fix_string_content(match):
        full = match.group(0)
        content = match.group(1)
        
        if not content:
            return full
        
        result = []
        i = 0
        
        while i < len(content):
            char = content[i]
            
            if char == '\\' and i + 1 < len(content):
                next_char = content[i + 1]
                two_chars = char + next_char
                
                # ‚úÖ Case 1: JSON escape h·ª£p l·ªá ‚Üí Gi·ªØ nguy√™n
                if two_chars in VALID_ESCAPES:
                    result.append(two_chars)
                    i += 2
                    continue
                
                # ‚úÖ Case 2: Unicode escape (\uXXXX) ‚Üí Gi·ªØ nguy√™n
                if next_char == 'u' and i + 5 < len(content):
                    hex_part = content[i+2:i+6]
                    if len(hex_part) == 4 and all(c in '0123456789ABCDEFabcdef' for c in hex_part):
                        result.append(content[i:i+6])
                        i += 6
                        continue
                
                # ‚úÖ Case 3: Backslash ƒê√É escape (\\) ‚Üí Gi·ªØ nguy√™n
                if next_char == '\\':
                    result.append('\\\\')
                    i += 2
                    continue
                
                # ‚ùå Case 4: LaTeX command ‚Üí C·∫¶N escape
                result.append('\\\\')
                i += 1
            else:
                result.append(char)
                i += 1
        
        return '"' + ''.join(result) + '"'
    
    string_pattern = r'"((?:[^"\\]|\\.)*)"'
    sanitized = re.sub(string_pattern, fix_string_content, text)
    return sanitized

def parse_json_safely(json_str: str, client) -> Optional[Dict]:
    """Parse JSON v·ªõi 3 l·ªõp b·∫£o v·ªá - ƒê√É C·∫¢I TI·∫æN"""
    
    # === L·ªöP 1: Th·ª≠ parse ngay l·∫≠p t·ª©c ===
    try:
        return json.loads(json_str, strict=False)
    except (json.JSONDecodeError, TypeError):
        pass

    # === L·ªöP 2: Clean + Sanitize ===
    cleaned = clean_json_string(json_str)
    sanitized = sanitize_latex_json(cleaned)
    
    try:
        return json.loads(sanitized, strict=False)
    except (json.JSONDecodeError, TypeError) as e:
        print(f"‚ö†Ô∏è L·ªói JSON sau sanitize (v·ªã tr√≠ {getattr(e, 'pos', 'unknown')}): {e.msg}")
        # Ch·ªâ in context n·∫øu c√≥ v·ªã tr√≠ l·ªói
        if hasattr(e, 'pos'):
            start = max(0, e.pos - 30)
            end = min(len(sanitized), e.pos + 30)
            print(f"Context: ...{sanitized[start:end]}...")

    # === L·ªöP 3: G·ªçi AI s·ª≠a ===
    print("ü§ñ G·ªçi AI s·ª≠a JSON...")
    try:
        # Thay v√¨ g·ª≠i 'cleaned', ta g·ª≠i 'sanitized' ƒë·ªÉ AI c√≥ th·ªÉ s·ª≠a d·ªÖ h∆°n
        repaired = repair_json_with_ai(sanitized, client)
        
        # AI c√≥ th·ªÉ tr·∫£ v·ªÅ nhi·ªÅu th·ª©, c·ªë g·∫Øng extract JSON h·ª£p l·ªá
        extracted_json = extract_valid_json(repaired)
        if extracted_json:
            # N·∫øu extract ƒë∆∞·ª£c, l·∫°i ph·∫£i sanitize l·∫°i v√¨ c√≥ th·ªÉ AI ch∆∞a escape ƒë√∫ng
            final_sanitized = sanitize_latex_json(extracted_json)
            try:
                return json.loads(final_sanitized, strict=False)
            except (json.JSONDecodeError, TypeError) as e:
                 print(f"‚ùå AI tr·∫£ v·ªÅ JSON nh∆∞ng v·∫´n l·ªói sau khi sanitize: {e}")
                 return None
        else:
            # N·∫øu kh√¥ng extract ƒë∆∞·ª£c, th·ª≠ parse nguy√™n vƒÉn
            try:
                return json.loads(repaired, strict=False)
            except (json.JSONDecodeError, TypeError) as e:
                 print(f"‚ùå Kh√¥ng th·ªÉ parse c·∫£ JSON ƒë∆∞·ª£c AI s·ª≠a: {e}")
                 return None

    except Exception as e:
        print(f"‚ùå L·ªñI nghi√™m tr·ªçng khi g·ªçi AI s·ª≠a JSON: {e}")
        traceback.print_exc()
        return None


def clean_json_string(text: str) -> str:
    """X√≥a markdown wrapper v√† l·∫•y ph·∫ßn JSON thu·∫ßn t√∫y"""
    if not text:
        return ""
    
    text = text.strip()
    
    # X√≥a markdown code block
    pattern = r"```(?:json)?(.*?)```"
    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
    if match:
        text = match.group(1).strip()
    
    # "SƒÉn" JSON b·∫±ng c√°ch t√¨m { ƒë·∫ßu v√† } cu·ªëi
    start = text.find('{')
    end = text.rfind('}')
    
    if start != -1 and end != -1 and end > start:
        return text[start:end + 1]
    
    return text
def generate_or_get_image(hinh_anh_data: Dict) -> tuple:
    """
    X·ª≠ l√Ω g·ªçi h√†m sinh ·∫£nh.
    Returns: (image_bytes, placeholder_text) - image_bytes l√† 1 object duy nh·∫•t
    """
    mo_ta = hinh_anh_data.get("mo_ta", hinh_anh_data.get("description", ""))
    mo_ta = str(mo_ta).strip()
    loai = hinh_anh_data.get("loai", "tu_mo_ta")
    
    if loai == "tu_mo_ta" and mo_ta:
        try:
            from common.text2Image import generate_image_from_text
            # H√†m n√†y tr·∫£ v·ªÅ 1 bytes object (ho·∫∑c None)
            image_bytes = generate_image_from_text(mo_ta)
            if image_bytes:
                return image_bytes, None
            else:
                # N·∫øu API tr·∫£ v·ªÅ None (do l·ªói m·∫°ng ho·∫∑c quota)
                return None, f"‚ö†Ô∏è [L·ªói sinh ·∫£nh] Server kh√¥ng tr·∫£ v·ªÅ ·∫£nh cho m√¥ t·∫£: {mo_ta}"
        except Exception as e:
            print(f"‚ùå L·ªói sinh ·∫£nh: {e}")
            return None, f"‚ö†Ô∏è [L·ªói Code] {str(e)}"
    
    placeholder = f"üñºÔ∏è [C·∫ßn ch√®n h√¨nh: {mo_ta}]"
    return None, placeholder

def insert_image_or_placeholder(doc: Document, hinh_anh_data: Dict):
    """Ch√®n ·∫£nh ho·∫∑c placeholder v√†o document"""
    image_bytes, placeholder = generate_or_get_image(hinh_anh_data)
    
    if image_bytes:
        try:
            image_stream = BytesIO(image_bytes)
            doc.add_picture(image_stream, width=Inches(4))
            doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER
        except Exception as e:
            print(f"‚ùå L·ªói ch√®n ·∫£nh: {e}")
            p = doc.add_paragraph()
            run = p.add_run(f"‚ö†Ô∏è [L·ªói ch√®n ·∫£nh: {str(e)}]")
            run.font.color.rgb = RGBColor(255, 0, 0)
            run.italic = True
    
    elif placeholder:
        p = doc.add_paragraph()
        run = p.add_run(placeholder)
        run.font.color.rgb = RGBColor(200, 0, 0)
        run.italic = True
        run.bold = True
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    return doc

class PromptBuilder:
    """
    Builder t·∫°o prompt ƒë·ªông - ƒê√£ s·ª≠a l·ªói xung ƒë·ªôt f-string v√† LaTeX
    """
    
    @staticmethod
    def build_json_structure_hint(question_type: str) -> str:
        # H√†m n√†y tr·∫£ v·ªÅ string th∆∞·ªùng (kh√¥ng ph·∫£i f-string) n√™n gi·ªØ nguy√™n 1 d·∫•u {}
        if question_type == "trac_nghiem_4_dap_an":
            return """
{
  "loai_de": "trac_nghiem_4_dap_an",
  "tong_so_cau": 80,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "nhan_biet",
      "phan": "Ph·∫ßn I",
      "noi_dung": "N·ªôi dung c√¢u h·ªèi...",
      "hinh_anh": { "co_hinh": true, "loai": "tu_mo_ta", "mo_ta": "M√¥ t·∫£..." },
      "dap_an": [
        {"ky_hieu": "A", "noi_dung": "ƒê√°p √°n A"},
        {"ky_hieu": "B", "noi_dung": "ƒê√°p √°n B"},
        {"ky_hieu": "C", "noi_dung": "ƒê√°p √°n C"},
        {"ky_hieu": "D", "noi_dung": "ƒê√°p √°n D"}
      ],
      "dap_an_dung": 2,
      "giai_thich": "Gi·∫£i th√≠ch..."
    }
  ]
}
"""
        elif question_type == "dung_sai":
            return """
{
  "loai_de": "dung_sai",
  "tong_so_cau": 40,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "thong_hieu",
      "phan": "Ph·∫ßn I",
      "doan_thong_tin": "N·ªôi dung...",
      "hinh_anh": { "co_hinh": true, "loai": "tu_mo_ta", "mo_ta": "M√¥ t·∫£..." },
      "cac_y": [
        {"ky_hieu": "a", "noi_dung": "...", "dung": false},
        {"ky_hieu": "b", "noi_dung": "...", "dung": true},
        {"ky_hieu": "c", "noi_dung": "...", "dung": false},
        {"ky_hieu": "d", "noi_dung": "...", "dung": true}
      ],
      "dap_an_dung_sai": "0101",
      "giai_thich": [
        {"y": "a", "noi_dung_y": "...", "ket_luan": "SAI", "giai_thich": "..."},
        {"y": "b", "noi_dung_y": "...", "ket_luan": "ƒê√öNG", "giai_thich": "..."}
      ]
    }
  ]
}
"""
        elif question_type == "tra_loi_ngan":
            return """
{
  "loai_de": "tra_loi_ngan",
  "tong_so_cau": 30,
  "cau_hoi": [
    {
      "stt": 1,
      "muc_do": "van_dung",
      "phan": "Ph·∫ßn I",
      "noi_dung": "N·ªôi dung...",
      "hinh_anh": { "co_hinh": true, "loai": "tu_mo_ta", "mo_ta": "..." },
      "dap_an": "[[k·∫øt qu·∫£]]",
      "giai_thich": "..."
    }
  ]
}
"""
        return "{}"

    @staticmethod
    def wrap_user_prompt(user_prompt: str, question_type: str) -> str:
        json_hint = PromptBuilder.build_json_structure_hint(question_type)
        
        # S·ª¨A L·ªñI T·∫†I ƒê√ÇY:
        # Trong f-string (f"""), d·∫•u ngo·∫∑c nh·ªçn c·ªßa LaTeX ph·∫£i nh√¢n ƒë√¥i th√†nh {{ }}
        # V√≠ d·ª•: \frac{1}{2} ph·∫£i vi·∫øt l√† \\frac{{1}}{{2}} ƒë·ªÉ Python kh√¥ng hi·ªÉu nh·∫ßm l√† bi·∫øn
        
        return f"""{user_prompt}

----------------
### Y√äU C·∫¶U NGHI√äM NG·∫∂T V·ªÄ D·ªÆ LI·ªÜU (B·∫ÆT BU·ªòC TU√ÇN TH·ª¶ 100%):

1. **FORMAT ƒê·∫¶U RA (QUAN TR·ªåNG NH·∫§T)**: 
   - CH·ªà TR·∫¢ V·ªÄ DUY NH·∫§T M·ªòT CHU·ªñI JSON thu·∫ßn t√∫y.
   - TUY·ªÜT ƒê·ªêI KH√îNG c√≥ l·ªùi m·ªü ƒë·∫ßu hay k·∫øt th√∫c (nh∆∞ "Here is result...").
   - **QUAN TR·ªåNG:** Ph·∫£i s·ª≠ d·ª•ng d·∫•u ngo·∫∑c k√©p (") cho key v√† value. KH√îNG d√πng d·∫•u ngo·∫∑c ƒë∆°n (').

2. **QUY T·∫ÆC LATEX (To√°n/L√Ω/H√≥a/Sinh):**
 - **KHOA H·ªåC T·ª∞ NHI√äN:**
    + B·∫ÆT BU·ªòC d√πng d·∫•u $ bao quanh c√¥ng th·ª©c.
    + Khi vi·∫øt trong JSON string, d·∫•u g·∫°ch ch√©o ph·∫£i ƒë∆∞·ª£c escape (nh√¢n ƒë√¥i).
    + V√≠ d·ª• ƒë√∫ng: "H√†m s·ªë $y = x^2$" ho·∫∑c "Ph√¢n s·ªë $\\\\frac{{1}}{{2}}$" (l∆∞u √Ω d·∫•u g·∫°ch ch√©o k√©p).
    + V√≠ d·ª• sai: "\\frac{{1}}{{2}}" (thi·∫øu escape) ho·∫∑c "$y$" (cho bi·∫øn ƒë∆°n l·∫ª kh√¥ng c·∫ßn thi·∫øt).

- **KHOA H·ªåC X√É H·ªòI:**
    + VI·∫æT VƒÇN B·∫¢N B√åNH TH∆Ø·ªúNG.
    + KH√îNG d√πng `$` cho c√°c con s·ªë th√¥ng th∆∞·ªùng, ng√†y th√°ng nƒÉm, ho·∫∑c danh t·ª´ ri√™ng.
    + V√≠ d·ª• ƒê√öNG: "Ng√†y 2/9/1945", "D√¢n s·ªë l√† 90 tri·ªáu ng∆∞·ªùi".
    + V√≠ d·ª• SAI (C·∫•m): "$Ng√†y 2/9/1945$", "$90 tri·ªáu$".

3. **H√åNH ·∫¢NH MINH H·ªåA (QUAN TR·ªåNG - B·∫ÆT BU·ªòC CHECK)**:
   - T∆∞ duy: "N·ªôi dung n√†y c√≥ c·∫ßn h√¨nh minh h·ªça ƒë·ªÉ h·ªçc sinh hi·ªÉu r√µ h∆°n kh√¥ng?"
   - √Åp d·ª•ng cho **M·ªåI Lƒ®NH V·ª∞C** (Khoa h·ªçc T·ª± nhi√™n & X√£ h·ªôi):
     + **To√°n/L√Ω/H√≥a**: N·∫øu c√≥ h√¨nh h·ªçc, ƒë·ªì th·ªã, m·∫°ch ƒëi·ªán, th√≠ nghi·ªám, c·∫•u tr√∫c ph√¢n t·ª≠... -> B·∫ÆT BU·ªòC ƒëi·ªÅn m√¥ t·∫£ v√†o `"mo_ta"`.
     + **S·ª≠/ƒê·ªãa/VƒÉn**: N·∫øu c√≥ l∆∞·ª£c ƒë·ªì tr·∫≠n ƒë√°nh, b·∫£n ƒë·ªì ƒë·ªãa l√Ω, bi·ªÉu ƒë·ªì d√¢n s·ªë, di t√≠ch l·ªãch s·ª≠, ch√¢n dung nh√¢n v·∫≠t... -> B·∫ÆT BU·ªòC ƒëi·ªÅn m√¥ t·∫£ v√†o `"mo_ta"`.
   - **C√°ch vi·∫øt m√¥ t·∫£ ("mo_ta")**:
     + Vi·∫øt chi ti·∫øt ƒë·ªÉ c√¥ng c·ª• v·∫Ω tranh (AI) c√≥ th·ªÉ t√°i t·∫°o l·∫°i ƒë∆∞·ª£c.
     + V√≠ d·ª• To√°n: "Tam gi√°c ABC vu√¥ng t·∫°i A, ƒë∆∞·ªùng cao AH..."
     + V√≠ d·ª• S·ª≠: "L∆∞·ª£c ƒë·ªì tr·∫≠n ƒêi·ªán Bi√™n Ph·ªß, c√°c m≈©i t√™n t·∫•n c√¥ng t·ª´ v√¢y quanh l√≤ng ch·∫£o..."
     + V√≠ d·ª• ƒê·ªãa: "B·∫£n ƒë·ªì h√¨nh ch·ªØ S c·ªßa Vi·ªát Nam, ƒë√°nh d·∫•u v·ªã tr√≠ th·ªß ƒë√¥ H√† N·ªôi..."

### M·∫™U JSON MONG MU·ªêN:
{json_hint}
"""
class DynamicDocxRenderer:
    """
    Renderer t·ª± ƒë·ªông th√≠ch ·ª©ng v·ªõi c·∫•u tr√∫c JSON
    """
    
    def __init__(self, doc: Document):
        self.doc = doc
    
    def render_title(self, data: Dict):
        """Render ti√™u ƒë·ªÅ t·ª± ƒë·ªông"""
        loai_de = data.get("loai_de", "").upper()
        title = self.doc.add_heading(f'ƒê·ªÄ {loai_de}', level=1)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    def auto_group_questions(self, data: Dict) -> Dict[str, List]:
        """
        T·ª± ƒë·ªông nh√≥m c√¢u h·ªèi v√† CHU·∫®N H√ìA key muc_do t·ª´ Ti·∫øng Vi·ªát sang code.
        Gi√∫p ng∆∞·ªùi d√πng tho·∫£i m√°i vi·∫øt prompt "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt"... m√† kh√¥ng b·ªã l·ªói file tr·∫Øng.
        """
        grouped = {}
        for cau in data.get("cau_hoi", []):
            # 1. L·∫•y d·ªØ li·ªáu th√¥ t·ª´ AI (v√≠ d·ª•: "V·∫≠n d·ª•ng", "Nh·∫≠n bi·∫øt", "Th√¥ng hi·ªÉu")
            # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ so s√°nh
            raw_muc_do = str(cau.get("muc_do", "unknown")).lower().strip()
            
            # 2. Logic "Phi√™n d·ªãch" th√¥ng minh (Mapping)
            # ∆Øu ti√™n check "cao" tr∆∞·ªõc ƒë·ªÉ ph√¢n bi·ªát "V·∫≠n d·ª•ng" v√† "V·∫≠n d·ª•ng cao"
            if "cao" in raw_muc_do:
                muc_do_chuan = "van_dung_cao"
            elif "d·ª•ng" in raw_muc_do or "dung" in raw_muc_do:
                muc_do_chuan = "van_dung"
            elif "th√¥ng" in raw_muc_do or "thong" in raw_muc_do:
                muc_do_chuan = "thong_hieu"
            elif "nh·∫≠n" in raw_muc_do or "nhan" in raw_muc_do:
                muc_do_chuan = "nhan_biet"
            else:
                # Tr∆∞·ªùng h·ª£p AI ghi n·ªôi dung l·∫°, m·∫∑c ƒë·ªãnh ƒë∆∞a v√†o V·∫≠n d·ª•ng 
                # ƒë·ªÉ ƒë·∫£m b·∫£o c√¢u h·ªèi v·∫´n hi·ªán ra trong file (tr√°nh l·ªói trang tr·∫Øng)
                muc_do_chuan = "van_dung" 
            
            # 3. Gom nh√≥m theo key chu·∫©n
            if muc_do_chuan not in grouped:
                grouped[muc_do_chuan] = []
            grouped[muc_do_chuan].append(cau)
        
        # S·∫Øp x·∫øp theo STT trong m·ªói nh√≥m
        for key in grouped:
            grouped[key].sort(key=lambda x: x.get("stt", 0))
        
        return grouped
    
    def get_section_title(self, muc_do: str) -> str:
        """
        T·∫°o ti√™u ƒë·ªÅ section d·ª±a tr√™n m·ª©c ƒë·ªô
        C√ì TH·ªÇ m·ªü r·ªông b·∫±ng config file
        """
        mapping = {
            "nhan_biet": "I. C√ÇU H·ªéI NH·∫¨N BI·∫æT",
            "thong_hieu": "II. C√ÇU H·ªéI TH√îNG HI·ªÇU",
            "van_dung": "III. C√ÇU H·ªéI V·∫¨N D·ª§NG",
            "van_dung_cao": "IV. C√ÇU H·ªéI V·∫¨N D·ª§NG CAO"
        }
        return mapping.get(muc_do, muc_do.upper())
    
    def render_question_trac_nghiem(self, cau: Dict):
        """Render c√¢u h·ªèi tr·∫Øc nghi·ªám 4 ƒë√°p √°n"""
        # C√¢u h·ªèi
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        process_text_with_latex(cau['noi_dung'], p)
        
        # H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # ƒê√°p √°n - TH√äM X·ª¨ L√ù LATEX
        for dap_an in cau.get("dap_an", []):
            p_da = self.doc.add_paragraph()
            run_ky_hieu = p_da.add_run(f"{dap_an['ky_hieu']}. ")
            process_text_with_latex(dap_an['noi_dung'], p_da) 
        
        # L·ªùi gi·∫£i
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        
        if "dap_an_dung" in cau:
            p_dung = self.doc.add_paragraph()
            p_dung.add_run(f"{cau['dap_an_dung']}").bold = True
            self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch - TH√äM X·ª¨ L√ù LATEX
        giai_thich = cau.get("giai_thich", "")
        for line in giai_thich.split("\n"):
            if line.strip():
                p_gt = self.doc.add_paragraph()
                process_text_with_latex(line.strip(), p_gt)  
        
        # K·∫øt lu·∫≠n - TH√äM X·ª¨ L√ù LATEX
        if "dap_an_dung" in cau:
            dap_an_num = cau['dap_an_dung']
            noi_dung_dap_an = cau['dap_an'][dap_an_num-1]['noi_dung']
            p_ket_luan = self.doc.add_paragraph()
            run = p_ket_luan.add_run("V·∫≠y ƒë√°p √°n ƒë√∫ng l√†: ")
            run.bold = True
            process_text_with_latex(noi_dung_dap_an, p_ket_luan, bold=True) 
    
    def render_question_dung_sai(self, cau: Dict):
        """Render c√¢u h·ªèi ƒë√∫ng/sai"""
        # S·ªë c√¢u
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}.").bold = True
        
        # ƒêo·∫°n th√¥ng tin - TH√äM X·ª¨ L√ù LATEX
        if cau.get("doan_thong_tin"):
            p_doan = self.doc.add_paragraph()
            process_text_with_latex(cau.get("doan_thong_tin", ""), p_doan)  
        
        # H√¨nh ·∫£nh
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # C√°c √Ω a, b, c, d - TH√äM X·ª¨ L√ù LATEX
        for y in cau.get("cac_y", []):
            p_y = self.doc.add_paragraph()
            p_y.add_run(f"{y['ky_hieu']}) ")
            process_text_with_latex(y['noi_dung'], p_y)  
        
        # L·ªùi gi·∫£i
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        
        p_da = self.doc.add_paragraph()
        p_da.add_run(cau.get("dap_an_dung_sai", "")).bold = True
        self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch t·ª´ng √Ω - TH√äM X·ª¨ L√ù LATEX
        for gt in cau.get("giai_thich", []):
            p_gt = self.doc.add_paragraph()
            p_gt.add_run("- ")
            process_text_with_latex(gt.get('noi_dung_y', ''), p_gt)  
            run_kl = p_gt.add_run(f" - {gt.get('ket_luan', 'SAI')}.")
            run_kl.bold = True
            
            if gt.get('giai_thich'):
                p_gt_detail = self.doc.add_paragraph()
                process_text_with_latex(gt.get('giai_thich', ''), p_gt_detail)  
    
    def render_question_tra_loi_ngan(self, cau: Dict):
        """Render c√¢u h·ªèi tr·∫£ l·ªùi ng·∫Øn"""
        # C√¢u h·ªèi
        p = self.doc.add_paragraph()
        p.add_run(f"C√¢u {cau['stt']}. ").bold = True
        p_noi_dung = self.doc.add_paragraph()
        process_text_with_latex(cau['noi_dung'], p_noi_dung)  
        
        # H√¨nh ·∫£nh (n·∫øu c√≥)
        hinh_anh = cau.get("hinh_anh", {})
        if hinh_anh.get("co_hinh"):
            insert_image_or_placeholder(self.doc, hinh_anh)
        
        # ƒê√°p √°n - TH√äM X·ª¨ L√ù LATEX
        p_da = self.doc.add_paragraph()
        run_label = p_da.add_run("ƒê√°p √°n: ")
        run_label.bold = True
        
        raw_ans = str(cau.get('dap_an', '')).strip()
        if raw_ans.startswith("[[") and raw_ans.endswith("]]"):
            final_ans = raw_ans
        else:
            final_ans = f"[[{raw_ans}]]"
        
        # X·ª¨ L√ù LATEX TRONG ƒê√ÅP √ÅN
        process_text_with_latex(final_ans, p_da, bold=True)  
        
        # L·ªùi gi·∫£i header
        p_lg = self.doc.add_paragraph()
        p_lg.add_run("L·ªùi gi·∫£i").bold = True
        self.doc.add_paragraph("####")
        
        # Gi·∫£i th√≠ch chi ti·∫øt - ƒê√É C√ì X·ª¨ L√ù LATEX
        giai_thich = cau.get("giai_thich", "")
        lines = giai_thich.replace('\\n', '\n').split('\n')
        
        for line in lines:
            text = line.strip()
            if not text or text == "####":
                continue
            
            is_bold = False
            if text.startswith("**") and text.endswith("**"):
                text = text[2:-2]
                is_bold = True
            
            check_text = text.replace('*', '').strip().lower()
            if check_text.startswith("v·∫≠y"):
                is_bold = True
                text = text.replace('**', '')

            p_gt = self.doc.add_paragraph()
            process_text_with_latex(text, p_gt, bold=is_bold)  
    
    def render_all(self, data: Dict):
        """
        Main render function - C√≥ h·ªó tr·ª£ chia PH·∫¶N (PART) b√™n trong M·ª©c ƒë·ªô
        """
        self.render_title(data)
        
        # 1. Auto-group theo m·ª©c ƒë·ªô (Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu...)
        grouped = self.auto_group_questions(data)
        
        # 2. Detect lo·∫°i ƒë·ªÅ
        loai_de = data.get("loai_de", "")
        
        # 3. Render t·ª´ng nh√≥m M·ª®C ƒê·ªò
        # Th·ª© t·ª± ∆∞u ti√™n render
        order_muc_do = ["nhan_biet", "thong_hieu", "van_dung", "van_dung_cao"]
        
        for muc_do in order_muc_do:
            if muc_do not in grouped:
                continue
            
            # L·∫•y danh s√°ch c√¢u h·ªèi trong m·ª©c ƒë·ªô n√†y
            questions = grouped[muc_do]
            if not questions:
                continue
            section_title = self.get_section_title(muc_do)
            self.doc.add_heading(section_title, level=2)
            current_phan = None

            for cau in questions:
                # L·∫•y t√™n ph·∫ßn c·ªßa c√¢u hi·ªán t·∫°i
                phan_cua_cau = str(cau.get("phan", "")).strip()
                
                # N·∫øu c√¢u n√†y thu·ªôc m·ªôt ph·∫ßn m·ªõi -> In Header Ph·∫ßn
                if phan_cua_cau and phan_cua_cau != current_phan:
                    # In ra header c·∫•p 3 (VD: Ph·∫ßn 1: ƒê·ªôi ng≈©...)
                    # D√πng m√†u ho·∫∑c in ƒë·∫≠m ƒë·ªÉ ph√¢n bi·ªát
                    p_phan = self.doc.add_heading(phan_cua_cau.upper(), level=3)
                    p_phan.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    current_phan = phan_cua_cau
                
                # Render n·ªôi dung c√¢u h·ªèi nh∆∞ b√¨nh th∆∞·ªùng
                if loai_de == "dung_sai":
                    self.render_question_dung_sai(cau)
                elif loai_de == "tra_loi_ngan":
                    self.render_question_tra_loi_ngan(cau)
                else:
                    self.render_question_trac_nghiem(cau)

def response2docx_flexible(
    file_path: str,
    prompt: str,
    file_name: str,
    project_id: str,
    creds: str,
    model_name: str,
    question_type: str = "trac_nghiem_4_dap_an",
    batch_name: Optional[str] = None
) -> Optional[str]:
    """
    Phi√™n b·∫£n c·∫£i ti·∫øn v·ªõi c∆° ch·∫ø fail-safe tri·ªát ƒë·ªÉ.
    Lu√¥n lu√¥n tr·∫£ v·ªÅ 1 file .docx, d√π AI c√≥ l·ªói hay kh√¥ng.
    """
    try:
        from api.callAPI import VertexClient
        from docx import Document # Import ·ªü ƒë√¢y ƒë·ªÉ ƒë·∫£m b·∫£o n·∫øu l·ªói ·ªü m·ª©c import th√¨ v·∫´n b·∫Øt ƒë∆∞·ª£c
        
        client = VertexClient(project_id, creds, model_name)
        
        if not batch_name:
            batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
        
        # 1. Wrap prompt v·ªõi JSON structure hint
        final_prompt = PromptBuilder.wrap_user_prompt(prompt, question_type)
        
        # 2. G·ª≠i request AI
        print("üì§ ƒêang g·ª≠i request t·ªõi AI...")
        ai_response = client.send_data_to_AI(final_prompt, file_path)
        
        # 3. Parse JSON v·ªõi c∆° ch·∫ø an to√†n
        print("üîÑ ƒêang parse JSON...")
        data = parse_json_safely(ai_response, client)
        
        if not data:
            print("‚ùå Kh√¥ng th·ªÉ parse JSON t·ª´ AI. S·ª≠ d·ª•ng ch·∫ø ƒë·ªô FAIL-SAFE.")
            # --- B∆Ø·ªöC FAIL-SAFE TRI·ªÜT ƒê·ªÇ ---
            # T·∫°o m·ªôt file .docx t·ªëi thi·ªÉu v·ªõi n·ªôi dung ph·∫£n h·ªìi th√¥ t·ª´ AI
            doc = Document()
            doc.add_heading(f'ƒê·ªÄ {question_type.upper()}', level=1).alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            doc.add_heading('PH·∫¢N H·ªíI T·ª™ AI (RAW)', level=2)
            # Th√™m ph·∫£n h·ªìi th√¥ ƒë·ªÉ ng∆∞·ªùi d√πng bi·∫øt AI ƒë√£ tr·∫£ v·ªÅ g√¨
            doc.add_paragraph(ai_response)
            
            doc.add_heading('L·ªñI', level=3)
            doc.add_paragraph('D·ªØ li·ªáu t·ª´ AI kh√¥ng ·ªü ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá v√† kh√¥ng th·ªÉ x·ª≠ l√Ω.')
            doc.add_paragraph('Vui l√≤ng ki·ªÉm tra l·∫°i prompt ho·∫∑c n·ªôi dung file ƒë·∫ßu v√†o.')
            
            print("üìù ƒêang l∆∞u file FAIL-SAFE...")
            output_path = save_document_securely(doc, batch_name, f"{file_name}_loi_parse")
            if output_path:
                print(f"‚úÖ ƒê√£ l∆∞u file FAIL-SAFE: {output_path}")
            else:
                print("‚ùå Kh√¥ng th·ªÉ l∆∞u file FAIL-SAFE.")
            return output_path # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file fail-safe

        print(f"‚úÖ Parse th√†nh c√¥ng: {data.get('tong_so_cau', 0)} c√¢u h·ªèi")
        
        # 4. Render DOCX ƒë·ªông (c≈©ng c√≥ th·ªÉ g√¢y l·ªói)
        print("üìù ƒêang t·∫°o DOCX...")
        doc = Document()
        renderer = DynamicDocxRenderer(doc)
        
        try:
            renderer.render_all(data)
            print("‚úÖ Render DOCX th√†nh c√¥ng")
        except Exception as e_render:
            print(f"‚ùå L·ªói khi render DOCX: {e_render}")
            print("üìù ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô FAIL-SAFE (d·ªØ li·ªáu th√¥)...")
            traceback.print_exc() # Ghi log l·ªói chi ti·∫øt
            
            # --- B∆Ø·ªöC FAIL-SAFE CHO RENDER ---
            # T·∫°o l·∫°i document m·ªõi t·ª´ ƒë·∫ßu, ch·ªâ ghi d·ªØ li·ªáu th√¥
            doc = Document()
            doc.add_heading(f'ƒê·ªÄ {question_type.upper()}', level=1).alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            doc.add_heading('D·ªÆ LI·ªÜU T·ª™ AI (RAW - JSON)', level=2)
            # Chuy·ªÉn d·ªØ li·ªáu sang string v√† th√™m v√†o doc
            raw_data_str = json.dumps(data, ensure_ascii=False, indent=2)
            doc.add_paragraph(raw_data_str)
            
            doc.add_heading('L·ªñI KHI X·ª¨ L√ù', level=3)
            doc.add_paragraph(f'L·ªói render: {e_render}')
            doc.add_paragraph('D·ªØ li·ªáu th√¥ ƒë√£ ƒë∆∞·ª£c l∆∞u. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c JSON.')
            
            print("üìù ƒêang l∆∞u file FAIL-SAFE (render l·ªói)...")
            output_path = save_document_securely(doc, batch_name, f"{file_name}_loi_render")
            if output_path:
                print(f"‚úÖ ƒê√£ l∆∞u file FAIL-SAFE (render l·ªói): {output_path}")
            else:
                print("‚ùå Kh√¥ng th·ªÉ l∆∞u file FAIL-SAFE (render l·ªói).")
            return output_path # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file fail-safe

        # 5. L∆∞u file (c√≥ th·ªÉ l·ªói do quy·ªÅn truy c·∫≠p, ·ªï ƒëƒ©a ƒë·∫ßy, v.v.)
        print("üíæ ƒêang l∆∞u file...")
        output_path = save_document_securely(doc, batch_name, file_name)
        
        if output_path:
            print(f"‚úÖ Ho√†n th√†nh: {output_path}")
        else:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u file (l·ªói t·ª´ h√†m save_document_securely).")
            # --- B∆Ø·ªöC FAIL-SAFE CHO L∆ØU FILE ---
            # Kh√¥ng th·ªÉ l∆∞u theo t√™n g·ªëc, th·ª≠ l∆∞u v·ªõi t√™n l·ªói
            print("üìù ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô FAIL-SAFE (l·ªói l∆∞u file)...")
            fallback_doc_path = os.path.join(ensure_output_folder_for_batch(batch_name), f"{file_name}_loi_luu.docx")
            try:
                doc.save(fallback_doc_path)
                print(f"‚úÖ ƒê√£ l∆∞u file FAIL-SAFE (l·ªói l∆∞u file): {fallback_doc_path}")
                return fallback_doc_path
            except Exception as e_save:
                print(f"‚ùå FAIL-SAFE c≈©ng th·∫•t b·∫°i khi l∆∞u: {e_save}")
                return None # Cu·ªëi c√πng v·∫´n th·∫•t b·∫°i
            
        return output_path

    except Exception as e_main:
        # B∆Ø·ªöC FAIL-SAFE CU·ªêI C√ôNG CHO TO√ÄN B·ªò H√ÄM
        print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG TRONG TO√ÄN B·ªò H√ÄM: {e_main}")
        traceback.print_exc()
        
        # T·∫°o m·ªôt file .docx tr·ªëng t·ªëi thi·ªÉu v·ªõi th√¥ng b√°o l·ªói
        try:
            doc = Document()
            doc.add_heading('L·ªñI H·ªÜ TH·ªêNG', level=1).alignment = WD_ALIGN_PARAGRAPH.CENTER
            doc.add_paragraph(f'L·ªói nghi√™m tr·ªçng: {e_main}')
            doc.add_paragraph('H·ªá th·ªëng kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu.')
            
            if not batch_name:
                batch_name = file_name.replace("_TN", "").replace("_DS", "").replace("_TLN", "")
            fallback_path = os.path.join(ensure_output_folder_for_batch(batch_name), f"{file_name}_loi_he_thong.docx")
            
            doc.save(fallback_path)
            print(f"‚úÖ ƒê√£ t·∫°o file FAIL-SAFE cu·ªëi c√πng: {fallback_path}")
            return fallback_path
        except Exception as e_final:
            print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o file FAIL-SAFE cu·ªëi c√πng: {e_final}")
            return None

def response2docx_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫Øc nghi·ªám 4 ƒë√°p √°n (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="trac_nghiem_4_dap_an",
        batch_name=batch_name
    )

def response2docx_dung_sai_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho ƒë√∫ng/sai (legacy)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="dung_sai",
        batch_name=batch_name
    )
    
def response2docx_tra_loi_ngan_json(file_path, prompt, file_name, project_id, creds, model_name, batch_name=None):
    """Wrapper cho tr·∫£ l·ªùi ng·∫Øn (legacy compatibility)"""
    return response2docx_flexible(
        file_path, prompt, file_name, project_id, creds, model_name,
        question_type="tra_loi_ngan",
        batch_name=batch_name
    )

class ConfigManager:
    """
    Qu·∫£n l√Ω c·∫•u h√¨nh qua file JSON
    Cho ph√©p thay ƒë·ªïi TO√ÄN B·ªò behavior m√† kh√¥ng s·ª≠a code
    """
    
    DEFAULT_CONFIG = {
        "section_mapping": {
            "nhan_biet": "I. C√ÇU H·ªéI NH·∫¨N BI·∫æT",
            "thong_hieu": "II. C√ÇU H·ªéI TH√îNG HI·ªÇU",
            "van_dung": "III. C√ÇU H·ªéI V·∫¨N D·ª§NG",
            "van_dung_cao": "IV. C√ÇU H·ªéI V·∫¨N D·ª§NG CAO" 
        },
        "section_order": ["nhan_biet", "thong_hieu", "van_dung", "van_dung_cao"],
        "auto_fix": True,
        "image_width_inches": 4,
        "retry_json_parse": 2
    }
    
    @classmethod
    def load_config(cls, config_path: str = "config.json") -> Dict:
        """Load config t·ª´ file ho·∫∑c d√πng default"""
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return cls.DEFAULT_CONFIG
    
    @classmethod
    def save_config(cls, config: Dict, config_path: str = "config.json"):
        """L∆∞u config ƒë·ªÉ t√°i s·ª≠ d·ª•ng"""
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)